"use strict";(self.webpackChunkaudio_queue_docs=self.webpackChunkaudio_queue_docs||[]).push([[330],{2775:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>a,metadata:()=>t,toc:()=>u});const t=JSON.parse('{"id":"api-reference/event-listeners","title":"Event Listeners","description":"Listen for audio events to create responsive user interfaces and track playback behavior.","source":"@site/docs/api-reference/event-listeners.md","sourceDirName":"api-reference","slug":"/api-reference/event-listeners","permalink":"/audio-queue-docs/api-reference/event-listeners","draft":false,"unlisted":false,"editUrl":"https://github.com/tonycarpenter21/audio-queue-docs/tree/main/docs/api-reference/event-listeners.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Pause & Resume","permalink":"/audio-queue-docs/api-reference/pause-resume"},"next":{"title":"Audio Information","permalink":"/audio-queue-docs/api-reference/audio-information"}}');var s=r(4848),i=r(8453);const a={},o="Event Listeners",l={},u=[{value:"onAudioStart",id:"onaudiostart",level:2},{value:"Syntax",id:"syntax",level:3},{value:"Parameters",id:"parameters",level:3},{value:"AudioStartInfo Properties",id:"audiostartinfo-properties",level:3},{value:"Examples",id:"examples",level:3},{value:"Real-world Usage",id:"real-world-usage",level:3},{value:"onAudioComplete",id:"onaudiocomplete",level:2},{value:"Syntax",id:"syntax-1",level:3},{value:"Parameters",id:"parameters-1",level:3},{value:"AudioCompleteInfo Properties",id:"audiocompleteinfo-properties",level:3},{value:"Examples",id:"examples-1",level:3},{value:"onAudioPause",id:"onaudiopause",level:2},{value:"Syntax",id:"syntax-2",level:3},{value:"Parameters",id:"parameters-2",level:3},{value:"Examples",id:"examples-2",level:3},{value:"Real-world Usage",id:"real-world-usage-1",level:3},{value:"onAudioResume",id:"onaudioresume",level:2},{value:"Syntax",id:"syntax-3",level:3},{value:"Parameters",id:"parameters-3",level:3},{value:"Examples",id:"examples-3",level:3},{value:"Real-world Usage",id:"real-world-usage-2",level:3},{value:"onAudioProgress",id:"onaudioprogress",level:2},{value:"Syntax",id:"syntax-4",level:3},{value:"Parameters",id:"parameters-4",level:3},{value:"AudioProgressInfo Properties",id:"audioprogressinfo-properties",level:3},{value:"Examples",id:"examples-4",level:3},{value:"Real-world Usage",id:"real-world-usage-3",level:3},{value:"onQueueChange",id:"onqueuechange",level:2},{value:"Syntax",id:"syntax-5",level:3},{value:"Parameters",id:"parameters-5",level:3},{value:"QueueSnapshot Properties",id:"queuesnapshot-properties",level:3},{value:"Examples",id:"examples-5",level:3},{value:"Real-world Usage",id:"real-world-usage-4",level:3},{value:"Error Handling with Events",id:"error-handling-with-events",level:2},{value:"Event Cleanup",id:"event-cleanup",level:2},{value:"Analytics and Tracking",id:"analytics-and-tracking",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"event-listeners",children:"Event Listeners"})}),"\n",(0,s.jsx)(n.p,{children:"Listen for audio events to create responsive user interfaces and track playback behavior."}),"\n",(0,s.jsx)(n.h2,{id:"onaudiostart",children:"onAudioStart"}),"\n",(0,s.jsx)(n.p,{children:"Listen for when audio begins playing on a specific channel."}),"\n",(0,s.jsx)(n.h3,{id:"syntax",children:"Syntax"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"onAudioStart(channelNumber: number, callback: (info: AudioStartInfo) => void): void\n"})}),"\n",(0,s.jsx)(n.h3,{id:"parameters",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"channelNumber"})," (number): The channel number to monitor"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"callback"})," (function): Function called when audio starts","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"info"})," (AudioStartInfo): Information about the started audio"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"audiostartinfo-properties",children:"AudioStartInfo Properties"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface AudioStartInfo {\r\n  audioElement: HTMLAudioElement;\r\n  currentTime: number;\r\n  duration: number;\r\n  fileName: string;\r\n  isLooping: boolean;\r\n  volume: number;\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"examples",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { onAudioStart, queueAudio } from 'audio-channel-queue';\r\n\r\n// Basic usage\r\nonAudioStart(0, (info) => {\r\n  console.log(`Started playing: ${info.fileName}`);\r\n  console.log(`Duration: ${info.duration}ms`);\r\n});\r\n\r\n// Update UI when audio starts\r\nonAudioStart(0, (info) => {\r\n  updateNowPlayingDisplay(info.fileName);\r\n  setProgressBarMax(info.duration);\r\n});\r\n\r\n// Queue some audio to trigger the event\r\nawait queueAudio('./music/song.mp3', 0);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"real-world-usage",children:"Real-world Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"class AudioUI {\r\n  constructor() {\r\n    this.setupAudioEventListeners();\r\n  }\r\n\r\n  private setupAudioEventListeners(): void {\r\n    onAudioStart(0, (info) => {\r\n      this.showPlayingState(info);\r\n      this.startProgressUpdates();\r\n    });\r\n  }\r\n\r\n  private showPlayingState(info: AudioStartInfo): void {\r\n    const playButton = document.getElementById('play-pause-btn');\r\n    const nowPlaying = document.getElementById('now-playing');\r\n    \r\n    if (playButton) {\r\n      playButton.textContent = '\u23f8\ufe0f Pause';\r\n      playButton.onclick = () => pauseChannel(0);\r\n    }\r\n    \r\n    if (nowPlaying) {\r\n      nowPlaying.innerHTML = `\r\n        <div class=\"track-info\">\r\n          <div class=\"track-name\">${info.fileName}</div>\r\n          <div class=\"track-duration\">${this.formatDuration(info.duration)}</div>\r\n        </div>\r\n      `;\r\n    }\r\n  }\r\n\r\n  private formatDuration(ms: number): string {\r\n    const seconds = Math.floor(ms / 1000);\r\n    const minutes = Math.floor(seconds / 60);\r\n    const remainingSeconds = seconds % 60;\r\n    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;\r\n  }\r\n\r\n  private startProgressUpdates(): void {\r\n    // Start interval to update progress bar\r\n    this.progressInterval = setInterval(() => {\r\n      const info = getCurrentAudioInfo(0);\r\n      if (info) {\r\n        this.updateProgressBar(info.currentTime, info.duration);\r\n      }\r\n    }, 100);\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"onaudiocomplete",children:"onAudioComplete"}),"\n",(0,s.jsx)(n.p,{children:"Listen for when audio finishes playing (either naturally or when interrupted)."}),"\n",(0,s.jsx)(n.h3,{id:"syntax-1",children:"Syntax"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"onAudioComplete(channelNumber: number, callback: (info: AudioCompleteInfo) => void): void\n"})}),"\n",(0,s.jsx)(n.h3,{id:"parameters-1",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"channelNumber"})," (number): The channel number to monitor"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"callback"})," (function): Function called when audio completes","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"info"})," (AudioCompleteInfo): Information about the completed audio"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"audiocompleteinfo-properties",children:"AudioCompleteInfo Properties"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface AudioCompleteInfo {\r\n  fileName: string;\r\n  playbackDuration: number;\r\n  remainingInQueue: number;\r\n  wasInterrupted: boolean;\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"examples-1",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { onAudioComplete, queueAudio } from 'audio-channel-queue';\r\n\r\n// Track completion stats\r\nonAudioComplete(0, (info) => {\r\n  console.log(`Completed: ${info.fileName}`);\r\n  console.log(`Played for: ${info.playbackDuration}ms`);\r\n  console.log(`Interrupted: ${info.wasInterrupted}`);\r\n  console.log(`Items left: ${info.remainingInQueue}`);\r\n});\r\n\r\n// Auto-queue next playlist item\r\nonAudioComplete(0, (info) => {\r\n  if (info.remainingInQueue === 0) {\r\n    loadNextPlaylist();\r\n  }\r\n});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"onaudiopause",children:"onAudioPause"}),"\n",(0,s.jsx)(n.p,{children:"Listen for when audio is paused on a specific channel."}),"\n",(0,s.jsx)(n.h3,{id:"syntax-2",children:"Syntax"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"onAudioPause(channelNumber: number, callback: () => void): void\n"})}),"\n",(0,s.jsx)(n.h3,{id:"parameters-2",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"channelNumber"})," (number): The channel number to monitor"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"callback"})," (function): Function called when audio is paused"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"examples-2",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { onAudioPause, pauseChannel } from 'audio-channel-queue';\r\n\r\n// Update UI when audio is paused\r\nonAudioPause(0, () => {\r\n  console.log('Music paused');\r\n  updatePlayButtonState('play');\r\n  showPausedOverlay();\r\n});\r\n\r\n// Track pause events for analytics\r\nonAudioPause(0, () => {\r\n  analytics.track('audio_paused', {\r\n    channel: 0,\r\n    timestamp: Date.now()\r\n  });\r\n});\r\n\r\n// Pause the audio to trigger the event\r\npauseChannel(0);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"real-world-usage-1",children:"Real-world Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"class MediaPlayer {\r\n  constructor() {\r\n    this.setupPauseHandling();\r\n  }\r\n\r\n  private setupPauseHandling(): void {\r\n    onAudioPause(0, () => {\r\n      this.onAudioPaused();\r\n    });\r\n  }\r\n\r\n  private onAudioPaused(): void {\r\n    // Update play/pause button\r\n    const playButton = document.getElementById('play-pause-btn');\r\n    if (playButton) {\r\n      playButton.textContent = '\u25b6\ufe0f Play';\r\n      playButton.onclick = () => resumeChannel(0);\r\n    }\r\n\r\n    // Show paused state in UI\r\n    const playerContainer = document.getElementById('player');\r\n    if (playerContainer) {\r\n      playerContainer.classList.add('paused');\r\n    }\r\n\r\n    // Pause any visual effects\r\n    this.stopVisualization();\r\n    \r\n    // Save current position for resume\r\n    const audioInfo = getCurrentAudioInfo(0);\r\n    if (audioInfo) {\r\n      this.savedPosition = audioInfo.currentTime;\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"onaudioresume",children:"onAudioResume"}),"\n",(0,s.jsx)(n.p,{children:"Listen for when audio is resumed on a specific channel."}),"\n",(0,s.jsx)(n.h3,{id:"syntax-3",children:"Syntax"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"onAudioResume(channelNumber: number, callback: () => void): void\n"})}),"\n",(0,s.jsx)(n.h3,{id:"parameters-3",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"channelNumber"})," (number): The channel number to monitor"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"callback"})," (function): Function called when audio is resumed"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"examples-3",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { onAudioResume, resumeChannel } from 'audio-channel-queue';\r\n\r\n// Update UI when audio resumes\r\nonAudioResume(0, () => {\r\n  console.log('Music resumed');\r\n  updatePlayButtonState('pause');\r\n  hidePausedOverlay();\r\n});\r\n\r\n// Track resume events\r\nonAudioResume(0, () => {\r\n  analytics.track('audio_resumed', {\r\n    channel: 0,\r\n    timestamp: Date.now()\r\n  });\r\n});\r\n\r\n// Resume the audio to trigger the event\r\nresumeChannel(0);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"real-world-usage-2",children:"Real-world Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"class MediaPlayer {\r\n  constructor() {\r\n    this.setupResumeHandling();\r\n  }\r\n\r\n  private setupResumeHandling(): void {\r\n    onAudioResume(0, () => {\r\n      this.onAudioResumed();\r\n    });\r\n  }\r\n\r\n  private onAudioResumed(): void {\r\n    // Update play/pause button\r\n    const playButton = document.getElementById('play-pause-btn');\r\n    if (playButton) {\r\n      playButton.textContent = '\u23f8\ufe0f Pause';\r\n      playButton.onclick = () => pauseChannel(0);\r\n    }\r\n\r\n    // Remove paused state from UI\r\n    const playerContainer = document.getElementById('player');\r\n    if (playerContainer) {\r\n      playerContainer.classList.remove('paused');\r\n    }\r\n\r\n    // Resume visual effects\r\n    this.startVisualization();\r\n    \r\n    // Continue progress tracking\r\n    this.resumeProgressTracking();\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"onaudioprogress",children:"onAudioProgress"}),"\n",(0,s.jsx)(n.p,{children:"Listen for real-time progress updates during audio playback."}),"\n",(0,s.jsx)(n.h3,{id:"syntax-4",children:"Syntax"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"onAudioProgress(channelNumber: number, callback: (info: AudioProgressInfo) => void): void\n"})}),"\n",(0,s.jsx)(n.h3,{id:"parameters-4",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"channelNumber"})," (number): The channel number to monitor"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"callback"})," (function): Function called during playback progress","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"info"})," (AudioProgressInfo): Current progress information"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"audioprogressinfo-properties",children:"AudioProgressInfo Properties"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface AudioProgressInfo {\r\n  currentTime: number;\r\n  duration: number;\r\n  fileName: string;\r\n  progress: number;\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"examples-4",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { onAudioProgress } from 'audio-channel-queue';\r\n\r\n// Update progress bar\r\nonAudioProgress(0, (info) => {\r\n  const percentage = Math.round(info.progress * 100);\r\n  updateProgressBar(percentage);\r\n  updateTimeDisplay(info.currentTime, info.duration);\r\n});\r\n\r\n// Trigger events at specific times\r\nonAudioProgress(0, (info) => {\r\n  // Fade out near the end\r\n  if (info.progress > 0.95) {\r\n    startFadeOut();\r\n  }\r\n  \r\n  // Show lyrics at specific timestamps\r\n  showLyricsAtTime(info.currentTime);\r\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"real-world-usage-3",children:"Real-world Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"class ProgressTracker {\r\n  constructor() {\r\n    this.setupProgressTracking();\r\n  }\r\n\r\n  private setupProgressTracking(): void {\r\n    onAudioProgress(0, (info) => {\r\n      this.updateProgress(info);\r\n      this.checkMilestones(info);\r\n    });\r\n  }\r\n\r\n  private updateProgress(info: AudioProgressInfo): void {\r\n    // Update progress bar\r\n    const progressBar = document.getElementById('progress-bar') as HTMLElement;\r\n    if (progressBar) {\r\n      progressBar.style.width = `${info.progress * 100}%`;\r\n    }\r\n\r\n    // Update time display\r\n    this.updateTimeDisplay(info.currentTime, info.duration);\r\n  }\r\n\r\n  private updateTimeDisplay(current: number, total: number): void {\r\n    const currentDisplay = document.getElementById('current-time');\r\n    const totalDisplay = document.getElementById('total-time');\r\n    \r\n    if (currentDisplay) {\r\n      currentDisplay.textContent = this.formatTime(current);\r\n    }\r\n    \r\n    if (totalDisplay) {\r\n      totalDisplay.textContent = this.formatTime(total);\r\n    }\r\n  }\r\n\r\n  private formatTime(milliseconds: number): string {\r\n    const seconds = Math.floor(milliseconds / 1000);\r\n    const minutes = Math.floor(seconds / 60);\r\n    const remainingSeconds = seconds % 60;\r\n    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;\r\n  }\r\n\r\n  private checkForBookmarks(info: AudioProgressInfo): void {\r\n    // Trigger events at specific timestamps\r\n    const currentSeconds = Math.floor(info.currentTime / 1000);\r\n    \r\n    if (currentSeconds === 30) {\r\n      this.triggerEvent('30-second-mark');\r\n    } else if (info.progress >= 0.5 && info.progress < 0.51) {\r\n      this.triggerEvent('halfway-point');\r\n    }\r\n  }\r\n\r\n  private triggerEvent(eventName: string): void {\r\n    console.log(`Event triggered: ${eventName}`);\r\n    // Dispatch custom events, show notifications, etc.\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"onqueuechange",children:"onQueueChange"}),"\n",(0,s.jsx)(n.p,{children:"Listen for changes to the audio queue."}),"\n",(0,s.jsx)(n.h3,{id:"syntax-5",children:"Syntax"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"onQueueChange(channelNumber: number, callback: (snapshot: QueueSnapshot) => void): void\n"})}),"\n",(0,s.jsx)(n.h3,{id:"parameters-5",children:"Parameters"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"channelNumber"})," (number): The channel number to monitor"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"callback"})," (function): Function called when queue changes","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"snapshot"})," (QueueSnapshot): Current state of the queue"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"queuesnapshot-properties",children:"QueueSnapshot Properties"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"interface QueueSnapshot {\r\n  items: QueueItem[];\r\n  totalItems: number;\r\n  currentlyPlaying: string | null;\r\n}\r\n\r\ninterface QueueItem {\r\n  fileName: string;\r\n  duration: number;\r\n  isCurrentlyPlaying: boolean;\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"examples-5",children:"Examples"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { onQueueChange, queueAudio } from 'audio-channel-queue';\r\n\r\n// Basic queue monitoring\r\nonQueueChange(0, (snapshot) => {\r\n  console.log(`Queue has ${snapshot.totalItems} items`);\r\n  console.log('Currently playing:', snapshot.currentlyPlaying);\r\n});\r\n\r\n// Update queue display\r\nonQueueChange(0, (snapshot) => {\r\n  updateQueueUI(snapshot.items);\r\n});\r\n\r\nfunction updateQueueUI(items: QueueItem[]): void {\r\n  const queueList = document.getElementById('queue-list');\r\n  if (!queueList) return;\r\n\r\n  queueList.innerHTML = items.map((item, index) => {\r\n    const status = item.isCurrentlyPlaying ? '\u25b6\ufe0f Playing' : `#${index + 1}`;\r\n    return `<li class=\"queue-item\">${status}: ${item.fileName}</li>`;\r\n  }).join('');\r\n}\n"})}),"\n",(0,s.jsx)(n.h3,{id:"real-world-usage-4",children:"Real-world Usage"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:'class PlaylistManager {\r\n  constructor() {\r\n    this.setupQueueMonitoring();\r\n  }\r\n\r\n  private setupQueueMonitoring(): void {\r\n    onQueueChange(0, (snapshot) => {\r\n      this.updatePlaylistDisplay(snapshot);\r\n      this.updateQueueStats(snapshot);\r\n    });\r\n  }\r\n\r\n  private updatePlaylistDisplay(snapshot: QueueSnapshot): void {\r\n    const playlistContainer = document.getElementById(\'playlist\');\r\n    if (!playlistContainer) return;\r\n\r\n    if (snapshot.totalItems === 0) {\r\n      playlistContainer.innerHTML = \'<div class="empty-playlist">No songs in queue</div>\';\r\n      return;\r\n    }\r\n\r\n    const playlistHTML = snapshot.items.map((item, index) => {\r\n      const isPlaying = item.isCurrentlyPlaying;\r\n      const duration = this.formatDuration(item.duration);\r\n      \r\n      return `\r\n        <div class="playlist-item ${isPlaying ? \'playing\' : \'\'}">\r\n          <div class="track-number">${isPlaying ? \'\u25b6\ufe0f\' : index + 1}</div>\r\n          <div class="track-info">\r\n            <div class="track-name">${item.fileName}</div>\r\n            <div class="track-duration">${duration}</div>\r\n          </div>\r\n          ${!isPlaying ? \'<button class="remove-btn" onclick="removeTrack(\' + index + \')">\u2716\ufe0f</button>\' : \'\'}\r\n        </div>\r\n      `;\r\n    }).join(\'\');\r\n\r\n    playlistContainer.innerHTML = playlistHTML;\r\n  }\r\n\r\n  private updateQueueStats(snapshot: QueueSnapshot): void {\r\n    const statsElement = document.getElementById(\'queue-stats\');\r\n    if (statsElement) {\r\n      const totalDuration = snapshot.items.reduce((sum, item) => sum + item.duration, 0);\r\n      statsElement.innerHTML = `\r\n        <div class="stat">\r\n          <span class="label">Tracks:</span>\r\n          <span class="value">${snapshot.totalItems}</span>\r\n        </div>\r\n        <div class="stat">\r\n          <span class="label">Total Time:</span>\r\n          <span class="value">${this.formatDuration(totalDuration)}</span>\r\n        </div>\r\n      `;\r\n    }\r\n  }\r\n\r\n  private formatDuration(ms: number): string {\r\n    const seconds = Math.floor(ms / 1000);\r\n    const minutes = Math.floor(seconds / 60);\r\n    const remainingSeconds = seconds % 60;\r\n    return `${minutes}:${remainingSeconds.toString().padStart(2, \'0\')}`;\r\n  }\r\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"error-handling-with-events",children:"Error Handling with Events"}),"\n",(0,s.jsxs)(n.p,{children:["While there isn't a dedicated ",(0,s.jsx)(n.code,{children:"onAudioError"})," event yet, you can implement error handling using the existing events:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"class AudioErrorHandler {\r\n  private errorCount: number = 0;\r\n  private maxErrors: number = 3;\r\n\r\n  constructor() {\r\n    this.setupErrorDetection();\r\n  }\r\n\r\n  private setupErrorDetection(): void {\r\n    let expectingStart = false;\r\n    let startTimeout: NodeJS.Timeout;\r\n\r\n    // Detect failed starts\r\n    onQueueChange(0, (snapshot) => {\r\n      if (snapshot.totalItems > 0 && snapshot.currentlyPlaying) {\r\n        expectingStart = true;\r\n        \r\n        // Clear any existing timeout\r\n        if (startTimeout) clearTimeout(startTimeout);\r\n        \r\n        // Audio should start within 5 seconds\r\n        startTimeout = setTimeout(() => {\r\n          if (expectingStart) {\r\n            this.handleError('Audio failed to start within timeout');\r\n          }\r\n        }, 5000);\r\n      }\r\n    });\r\n\r\n    onAudioStart(0, () => {\r\n      expectingStart = false;\r\n      if (startTimeout) {\r\n        clearTimeout(startTimeout);\r\n      }\r\n    });\r\n\r\n    // Detect suspicious completions (very short playback)\r\n    onAudioComplete(0, (info) => {\r\n      if (info.playbackDuration < 1000 && !info.wasInterrupted) {\r\n        this.handleError(`Suspicious completion: ${info.fileName} played for only ${info.playbackDuration}ms`);\r\n      }\r\n    });\r\n  }\r\n\r\n  private handleError(message: string): void {\r\n    this.errorCount++;\r\n    console.error(`Audio Error ${this.errorCount}: ${message}`);\r\n    \r\n    if (this.errorCount >= this.maxErrors) {\r\n      console.error('Too many audio errors - audio system may be unstable');\r\n      // Could disable audio system or show user notification\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"event-cleanup",children:"Event Cleanup"}),"\n",(0,s.jsx)(n.p,{children:"Remember to clean up event listeners when no longer needed:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"import { offAudioStart, offAudioComplete, offQueueChange } from 'audio-channel-queue';\r\n\r\nclass AudioComponent {\r\n  private startHandler = (info: AudioStartInfo) => {\r\n    console.log(`Started: ${info.fileName}`);\r\n  };\r\n\r\n  constructor() {\r\n    // Set up listeners\r\n    onAudioStart(0, this.startHandler);\r\n  }\r\n\r\n  destroy(): void {\r\n    // Clean up listeners\r\n    offAudioStart(0, this.startHandler);\r\n    // Note: Some cleanup functions may not exist yet - check package documentation\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"analytics-and-tracking",children:"Analytics and Tracking"}),"\n",(0,s.jsx)(n.p,{children:"Use events to build comprehensive analytics:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"class AudioAnalytics {\r\n  private sessionStart: number = Date.now();\r\n  private playbackStats: Map<string, { count: number; totalDuration: number }> = new Map();\r\n  \r\n  constructor() {\r\n    this.setupAnalytics();\r\n  }\r\n  \r\n  private setupAnalytics(): void {\r\n    onAudioStart(0, (info) => {\r\n      this.trackAudioStart(info);\r\n    });\r\n    \r\n    onAudioComplete(0, (info) => {\r\n      this.trackAudioComplete(info);\r\n    });\r\n    \r\n    onAudioProgress(0, (info) => {\r\n      this.trackProgress(info);\r\n    });\r\n  }\r\n  \r\n  private trackAudioStart(info: AudioStartInfo): void {\r\n    console.log(`\ud83d\udcca Analytics: Started ${info.fileName}`);\r\n    \r\n    // Initialize or increment play count\r\n    const stats = this.playbackStats.get(info.fileName) || { count: 0, totalDuration: 0 };\r\n    stats.count++;\r\n    this.playbackStats.set(info.fileName, stats);\r\n  }\r\n  \r\n  private trackAudioComplete(info: AudioCompleteInfo): void {\r\n    console.log(`\ud83d\udcca Analytics: Completed ${info.fileName} (${info.playbackDuration}ms)`);\r\n    \r\n    // Update duration stats\r\n    const stats = this.playbackStats.get(info.fileName);\r\n    if (stats) {\r\n      stats.totalDuration += info.playbackDuration;\r\n      this.playbackStats.set(info.fileName, stats);\r\n    }\r\n    \r\n    // Track completion rate\r\n    if (!info.wasInterrupted) {\r\n      console.log(`\u2705 ${info.fileName} played to completion`);\r\n    } else {\r\n      console.log(`\u23f9\ufe0f ${info.fileName} was interrupted`);\r\n    }\r\n  }\r\n  \r\n  private trackProgress(info: AudioProgressInfo): void {\r\n    // Track milestone progress (only log once per milestone)\r\n    const milestones = [0.25, 0.5, 0.75];\r\n    for (const milestone of milestones) {\r\n      if (info.progress >= milestone && info.progress < milestone + 0.01) {\r\n        console.log(`\ud83d\udcca Analytics: ${info.fileName} reached ${milestone * 100}%`);\r\n      }\r\n    }\r\n  }\r\n  \r\n  getSessionReport(): object {\r\n    const sessionDuration = Date.now() - this.sessionStart;\r\n    const totalTracks = this.playbackStats.size;\r\n    const totalPlaybacks = Array.from(this.playbackStats.values()).reduce((sum, stat) => sum + stat.count, 0);\r\n    \r\n    return {\r\n      sessionDuration,\r\n      totalTracks,\r\n      totalPlaybacks,\r\n      playbackStats: Object.fromEntries(this.playbackStats)\r\n    };\r\n  }\r\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"Now that you understand the event system, explore:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/audio-queue-docs/api-reference/audio-information",children:"Audio Information"})})," - Get real-time audio data"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/audio-queue-docs/api-reference/queue-management",children:"Queue Management"})})," - Control audio queues"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/audio-queue-docs/api-reference/volume-control",children:"Volume Control"})})," - Manage audio levels"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"../examples/basic-usage",children:"Examples"})})," - Real-world event handling patterns"]}),"\n"]})]})}function c(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var t=r(6540);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);