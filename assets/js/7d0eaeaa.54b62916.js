"use strict";(self.webpackChunkaudio_queue_docs=self.webpackChunkaudio_queue_docs||[]).push([[703],{1300:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>a,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"core-concepts/audio-lifecycle","title":"Audio Lifecycle","description":"Understanding the complete audio lifecycle from queueing to completion, including all states, transitions, and events.","source":"@site/docs/core-concepts/audio-lifecycle.md","sourceDirName":"core-concepts","slug":"/core-concepts/audio-lifecycle","permalink":"/audio-queue-docs/core-concepts/audio-lifecycle","draft":false,"unlisted":false,"editUrl":"https://github.com/tonycarpenter21/audio-queue-docs/tree/main/docs/core-concepts/audio-lifecycle.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Event System","permalink":"/audio-queue-docs/core-concepts/event-system"},"next":{"title":"Performance & Memory Management","permalink":"/audio-queue-docs/core-concepts/performance-memory"}}');var o=r(4848),i=r(8453);const a={},s="Audio Lifecycle",l={},c=[{value:"Audio Lifecycle Overview",id:"audio-lifecycle-overview",level:2},{value:"Lifecycle Phases",id:"lifecycle-phases",level:2},{value:"Phase 1: Queuing",id:"phase-1-queuing",level:3},{value:"Phase 2: Loading &amp; Preparation",id:"phase-2-loading--preparation",level:3},{value:"Phase 3: Active Playback",id:"phase-3-active-playback",level:3},{value:"Phase 4: Completion or Interruption",id:"phase-4-completion-or-interruption",level:3},{value:"Complete Lifecycle State Machine",id:"complete-lifecycle-state-machine",level:2},{value:"Lifecycle Monitoring and Analytics",id:"lifecycle-monitoring-and-analytics",level:2},{value:"Error Handling in Lifecycle",id:"error-handling-in-lifecycle",level:2},{value:"Audio Loading States and Error Handling",id:"audio-loading-states-and-error-handling",level:2},{value:"Browser Compatibility and Network Error Handling",id:"browser-compatibility-and-network-error-handling",level:2},{value:"Performance Monitoring and Memory Management",id:"performance-monitoring-and-memory-management",level:2},{value:"Complete Lifecycle Manager",id:"complete-lifecycle-manager",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"audio-lifecycle",children:"Audio Lifecycle"})}),"\n",(0,o.jsx)(n.p,{children:"Understanding the complete audio lifecycle from queueing to completion, including all states, transitions, and events."}),"\n",(0,o.jsx)(n.h2,{id:"audio-lifecycle-overview",children:"Audio Lifecycle Overview"}),"\n",(0,o.jsx)(n.p,{children:"Every audio file in the audio-channel-queue system goes through a well-defined lifecycle with distinct phases, state transitions, and events. Understanding this lifecycle is crucial for building robust audio applications."}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"import { \r\n  queueAudio, \r\n  onAudioStart, \r\n  onAudioProgress, \r\n  onAudioComplete, \r\n  getCurrentAudioInfo \r\n} from 'audio-channel-queue';\r\n\r\n// Complete lifecycle example\r\nasync function demonstrateLifecycle(): Promise<void> {\r\n  console.log('1. Queueing audio...');\r\n  await queueAudio('./audio/demo.mp3'); // Using default channel 0\r\n  \r\n  // 2. Audio starts playing\r\n  onAudioStart(0, (info) => {\r\n    console.log(`2. Audio started: ${info.fileName}`);\r\n    console.log(`   Duration: ${info.duration}ms`);\r\n    console.log(`   Volume: ${info.volume}`);\r\n  });\r\n  \r\n  // 3. Progress updates during playback\r\n  onAudioProgress(0, (info) => {\r\n    const percentage = Math.round(info.progress * 100);\r\n    console.log(`3. Progress: ${percentage}% (${info.currentTime}/${info.duration}ms)`);\r\n  });\r\n  \r\n  // 4. Audio completes\r\n  onAudioComplete(0, (info) => {\r\n    console.log(`4. Audio completed: ${info.fileName}`);\r\n    console.log(`   Played for: ${info.playbackDuration}ms`);\r\n    console.log(`   Was interrupted: ${info.wasInterrupted}`);\r\n    console.log(`   Remaining in queue: ${info.remainingInQueue}`);\r\n  });\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"lifecycle-phases",children:"Lifecycle Phases"}),"\n",(0,o.jsx)(n.h3,{id:"phase-1-queuing",children:"Phase 1: Queuing"}),"\n",(0,o.jsx)(n.p,{children:"Audio enters the system when queued on a channel:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio, queueAudioPriority, getQueueSnapshot } from 'audio-channel-queue';\r\n\r\nclass AudioLifecycleTracker {\r\n  async trackQueuePhase(): Promise<void> {\r\n    console.log('\ud83d\udccb Phase 1: Queuing');\r\n    \r\n    // Standard queueing - added to end of queue (using default channel 0)\r\n    await queueAudio('./audio/track1.mp3');\r\n    console.log('\u2713 track1.mp3 queued normally');\r\n    \r\n    await queueAudio('./audio/track2.mp3');\r\n    console.log('\u2713 track2.mp3 queued normally');\r\n    \r\n    // Priority queueing - interrupts current playback\r\n    await queueAudioPriority('./audio/urgent.mp3');\r\n    console.log('\u2713 urgent.mp3 queued with priority');\r\n    \r\n    // Check queue state after queueing\r\n    const snapshot = getQueueSnapshot(); // Using default channel 0\r\n    console.log(`Queue now has ${snapshot.totalItems} items`);\r\n    snapshot.items.forEach((item, index) => {\r\n      const status = item.isCurrentlyPlaying ? 'Playing' : 'Queued';\r\n      console.log(`  ${item.position}. ${status}: ${item.fileName}`);\r\n    });\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"phase-2-loading--preparation",children:"Phase 2: Loading & Preparation"}),"\n",(0,o.jsx)(n.p,{children:"Before playback begins, the audio element is prepared:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"import { onAudioStart } from 'audio-channel-queue';\r\n\r\nclass LoadingPhaseTracker {\r\n  setupLoadingTracking(): void {\r\n    console.log('\ud83d\udcc2 Phase 2: Loading & Preparation');\r\n    \r\n    onAudioStart(0, (info) => {\r\n      console.log(`\u2713 Audio loaded and ready: ${info.fileName}`);\r\n      console.log(`  Element created: ${info.audioElement.tagName}`);\r\n      console.log(`  Source set: ${info.audioElement.src}`);\r\n      console.log(`  Duration determined: ${info.duration}ms`);\r\n      console.log(`  Initial position: ${info.currentTime}ms`);\r\n      \r\n      // Audio element is fully loaded and playback has started\r\n      this.onAudioLoaded(info);\r\n    });\r\n  }\r\n  \r\n  private onAudioLoaded(info: AudioStartInfo): void {\r\n    // The audio file has been successfully loaded\r\n    // The HTML audio element is created and configured\r\n    // Playback has begun\r\n    console.log(`Loading complete for ${info.fileName}`);\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"phase-3-active-playback",children:"Phase 3: Active Playback"}),"\n",(0,o.jsx)(n.p,{children:"During active playback, continuous progress events are fired:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"import { onAudioProgress, AudioProgressInfo } from 'audio-channel-queue';\r\n\r\nclass PlaybackPhaseTracker {\r\n  private milestones: Set<number> = new Set();\r\n  \r\n  setupPlaybackTracking(): void {\r\n    console.log('\u25b6\ufe0f Phase 3: Active Playback');\r\n    \r\n    onAudioProgress(0, (info) => {\r\n      this.trackPlaybackProgress(info);\r\n      this.checkMilestones(info);\r\n      this.updateUI(info);\r\n    });\r\n  }\r\n  \r\n  private trackPlaybackProgress(info: AudioProgressInfo): void {\r\n    // Continuous playback monitoring\r\n    const percentage = Math.round(info.progress * 100);\r\n    \r\n    // Log progress periodically (every 10%)\r\n    if (percentage % 10 === 0 && !this.milestones.has(percentage)) {\r\n      console.log(`\u23f8\ufe0f Progress: ${percentage}% - ${info.fileName}`);\r\n      console.log(`   Time: ${info.currentTime}ms / ${info.duration}ms`);\r\n      this.milestones.add(percentage);\r\n    }\r\n  }\r\n  \r\n  private checkMilestones(info: AudioProgressInfo): void {\r\n    // Check for important milestones\r\n    const progress = info.progress;\r\n    \r\n    if (progress >= 0.1 && progress < 0.11) {\r\n      this.onEarlyPlayback(info);\r\n    } else if (progress >= 0.5 && progress < 0.51) {\r\n      this.onMidpoint(info);\r\n    } else if (progress >= 0.9 && progress < 0.91) {\r\n      this.onNearingEnd(info);\r\n    }\r\n  }\r\n  \r\n  private onEarlyPlayback(info: AudioProgressInfo): void {\r\n    console.log(`\ud83c\udfb5 Early playback (10%): ${info.fileName}`);\r\n    // Good time to start preloading next track\r\n  }\r\n  \r\n  private onMidpoint(info: AudioProgressInfo): void {\r\n    console.log(`\ud83c\udfaf Midpoint reached (50%): ${info.fileName}`);\r\n    // Analytics milestone, UI updates\r\n  }\r\n  \r\n  private onNearingEnd(info: AudioProgressInfo): void {\r\n    console.log(`\ud83c\udfc1 Nearing end (90%): ${info.fileName}`);\r\n    // Prepare for transition to next track\r\n  }\r\n  \r\n  private updateUI(info: AudioProgressInfo): void {\r\n    // Update progress bar, time display, etc.\r\n    const percentage = Math.round(info.progress * 100);\r\n    // UI update logic here\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h3,{id:"phase-4-completion-or-interruption",children:"Phase 4: Completion or Interruption"}),"\n",(0,o.jsx)(n.p,{children:"Audio lifecycle ends either naturally or through interruption:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"import { onAudioComplete, stopCurrentAudioInChannel } from 'audio-channel-queue';\r\n\r\nclass CompletionPhaseTracker {\r\n  setupCompletionTracking(): void {\r\n    console.log('\ud83c\udfc1 Phase 4: Completion or Interruption');\r\n    \r\n    onAudioComplete(0, (info) => {\r\n      this.analyzeCompletion(info);\r\n      this.handlePostCompletion(info);\r\n    });\r\n  }\r\n  \r\n  private analyzeCompletion(info: AudioCompleteInfo): void {\r\n    console.log(`Completion analysis for: ${info.fileName}`);\r\n    console.log(`  Playback duration: ${info.playbackDuration}ms`);\r\n    console.log(`  Was interrupted: ${info.wasInterrupted}`);\r\n    console.log(`  Remaining in queue: ${info.remainingInQueue}`);\r\n    \r\n    if (info.wasInterrupted) {\r\n      this.handleInterruption(info);\r\n    } else {\r\n      this.handleNaturalCompletion(info);\r\n    }\r\n  }\r\n  \r\n  private handleInterruption(info: AudioCompleteInfo): void {\r\n    console.log(`\u23f9\ufe0f Interrupted: ${info.fileName}`);\r\n    console.log(`   Played ${info.playbackDuration}ms before interruption`);\r\n    \r\n    // Log interruption reason\r\n    this.logInterruptionReason(info);\r\n    \r\n    // Update analytics\r\n    this.trackInterruption(info);\r\n  }\r\n  \r\n  private handleNaturalCompletion(info: AudioCompleteInfo): void {\r\n    console.log(`\u2705 Completed naturally: ${info.fileName}`);\r\n    console.log(`   Full playback duration: ${info.playbackDuration}ms`);\r\n    \r\n    // Update completion stats\r\n    this.trackSuccessfulCompletion(info);\r\n    \r\n    // Consider auto-advancing or looping\r\n    this.handleSuccessfulCompletion(info);\r\n  }\r\n  \r\n  private handlePostCompletion(info: AudioCompleteInfo): void {\r\n    if (info.remainingInQueue === 0) {\r\n      this.onQueueEmpty();\r\n    } else {\r\n      this.onMoreItemsInQueue(info.remainingInQueue);\r\n    }\r\n  }\r\n  \r\n  private logInterruptionReason(info: AudioCompleteInfo): void {\r\n    // This is called when audio is stopped early\r\n    console.log(`Interruption logged for ${info.fileName}`);\r\n  }\r\n  \r\n  private trackInterruption(info: AudioCompleteInfo): void {\r\n    // Analytics tracking for interruptions\r\n    console.log(`Analytics: Interruption - ${info.fileName}`);\r\n  }\r\n  \r\n  private trackSuccessfulCompletion(info: AudioCompleteInfo): void {\r\n    // Analytics tracking for successful completions\r\n    console.log(`Analytics: Completion - ${info.fileName}`);\r\n  }\r\n  \r\n  private handleSuccessfulCompletion(info: AudioCompleteInfo): void {\r\n    // Handle successful completion logic\r\n    console.log(`Success handler for ${info.fileName}`);\r\n  }\r\n  \r\n  private onQueueEmpty(): void {\r\n    console.log('\ud83d\udd15 Queue is now empty - session ended');\r\n    // Handle end of playback session\r\n  }\r\n  \r\n  private onMoreItemsInQueue(remaining: number): void {\r\n    console.log(`\u25b6\ufe0f Queue continues with ${remaining} items`);\r\n    // Next item will automatically start playing\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"complete-lifecycle-state-machine",children:"Complete Lifecycle State Machine"}),"\n",(0,o.jsx)(n.p,{children:"Here's a comprehensive state machine that tracks the entire audio lifecycle:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"enum AudioLifecycleState {\r\n  IDLE = 'idle',\r\n  QUEUED = 'queued',\r\n  LOADING = 'loading',\r\n  PLAYING = 'playing',\r\n  PAUSED = 'paused',\r\n  COMPLETING = 'completing',\r\n  COMPLETED = 'completed',\r\n  INTERRUPTED = 'interrupted'\r\n}\r\n\r\nclass AudioLifecycleStateMachine {\r\n  private state: AudioLifecycleState = AudioLifecycleState.IDLE;\r\n  private currentAudio: string | null = null;\r\n  private startTime: number = 0;\r\n  private channel: number;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.channel = channel;\r\n    this.setupLifecycleTracking();\r\n  }\r\n  \r\n  private setupLifecycleTracking(): void {\r\n    // Track queue changes to detect queuing\r\n    onQueueChange(this.channel, (snapshot) => {\r\n      if (snapshot.totalItems > 0 && this.state === AudioLifecycleState.IDLE) {\r\n        this.transitionTo(AudioLifecycleState.QUEUED);\r\n      } else if (snapshot.totalItems === 0) {\r\n        this.transitionTo(AudioLifecycleState.IDLE);\r\n      }\r\n    });\r\n    \r\n    // Track audio start\r\n    onAudioStart(this.channel, (info) => {\r\n      this.currentAudio = info.fileName;\r\n      this.startTime = Date.now();\r\n      this.transitionTo(AudioLifecycleState.PLAYING);\r\n    });\r\n    \r\n    // Track progress for state transitions\r\n    onAudioProgress(this.channel, (info) => {\r\n      if (info.progress > 0.9 && this.state === AudioLifecycleState.PLAYING) {\r\n        this.transitionTo(AudioLifecycleState.COMPLETING);\r\n      }\r\n    });\r\n    \r\n    // Track completion\r\n    onAudioComplete(this.channel, (info) => {\r\n      if (info.wasInterrupted) {\r\n        this.transitionTo(AudioLifecycleState.INTERRUPTED);\r\n      } else {\r\n        this.transitionTo(AudioLifecycleState.COMPLETED);\r\n      }\r\n      \r\n      // Reset for next audio\r\n      setTimeout(() => {\r\n        if (info.remainingInQueue > 0) {\r\n          this.transitionTo(AudioLifecycleState.QUEUED);\r\n        } else {\r\n          this.transitionTo(AudioLifecycleState.IDLE);\r\n        }\r\n      }, 100);\r\n    });\r\n  }\r\n  \r\n  private transitionTo(newState: AudioLifecycleState): void {\r\n    const oldState = this.state;\r\n    this.state = newState;\r\n    \r\n    console.log(`\ud83d\udd04 Lifecycle: ${oldState} \u2192 ${newState}`);\r\n    \r\n    // Handle state-specific logic\r\n    this.handleStateEntry(newState, oldState);\r\n  }\r\n  \r\n  private handleStateEntry(state: AudioLifecycleState, previousState: AudioLifecycleState): void {\r\n    const elapsed = Date.now() - this.startTime;\r\n    \r\n    switch (state) {\r\n      case AudioLifecycleState.IDLE:\r\n        console.log('\ud83d\udca4 Audio system is idle');\r\n        this.onIdle();\r\n        break;\r\n        \r\n      case AudioLifecycleState.QUEUED:\r\n        console.log(`\ud83d\udccb Audio queued: ${this.currentAudio || 'Unknown'}`);\r\n        this.onQueued();\r\n        break;\r\n        \r\n      case AudioLifecycleState.PLAYING:\r\n        console.log(`\u25b6\ufe0f Audio playing: ${this.currentAudio}`);\r\n        this.onPlaying();\r\n        break;\r\n        \r\n      case AudioLifecycleState.COMPLETING:\r\n        console.log(`\ud83c\udfc1 Audio completing: ${this.currentAudio} (${elapsed}ms elapsed)`);\r\n        this.onCompleting();\r\n        break;\r\n        \r\n      case AudioLifecycleState.COMPLETED:\r\n        console.log(`\u2705 Audio completed: ${this.currentAudio} (${elapsed}ms total)`);\r\n        this.onCompleted();\r\n        break;\r\n        \r\n      case AudioLifecycleState.INTERRUPTED:\r\n        console.log(`\u23f9\ufe0f Audio interrupted: ${this.currentAudio} (${elapsed}ms elapsed)`);\r\n        this.onInterrupted();\r\n        break;\r\n    }\r\n  }\r\n  \r\n  // State-specific handlers\r\n  private onIdle(): void {\r\n    this.currentAudio = null;\r\n    this.startTime = 0;\r\n    // Maybe start background music or show idle UI\r\n  }\r\n  \r\n  private onQueued(): void {\r\n    // Audio is in queue, waiting to play\r\n    // Good time to show \"Loading...\" UI\r\n  }\r\n  \r\n  private onPlaying(): void {\r\n    // Audio is actively playing\r\n    // Update UI to show play state, enable pause/skip controls\r\n  }\r\n  \r\n  private onCompleting(): void {\r\n    // Audio is near end\r\n    // Good time to preload next track or prepare transition\r\n  }\r\n  \r\n  private onCompleted(): void {\r\n    // Audio finished successfully\r\n    // Update analytics, show completion feedback\r\n  }\r\n  \r\n  private onInterrupted(): void {\r\n    // Audio was stopped early\r\n    // Log interruption, handle cleanup\r\n  }\r\n  \r\n  // Public interface\r\n  getCurrentState(): AudioLifecycleState {\r\n    return this.state;\r\n  }\r\n  \r\n  getCurrentAudio(): string | null {\r\n    return this.currentAudio;\r\n  }\r\n  \r\n  getElapsedTime(): number {\r\n    return this.startTime > 0 ? Date.now() - this.startTime : 0;\r\n  }\r\n  \r\n  isActive(): boolean {\r\n    return [\r\n      AudioLifecycleState.QUEUED,\r\n      AudioLifecycleState.PLAYING,\r\n      AudioLifecycleState.COMPLETING\r\n    ].includes(this.state);\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"lifecycle-monitoring-and-analytics",children:"Lifecycle Monitoring and Analytics"}),"\n",(0,o.jsx)(n.p,{children:"Track audio lifecycle for performance monitoring and analytics:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"class AudioLifecycleAnalytics {\r\n  private lifecycleEvents: Array<{\r\n    timestamp: number;\r\n    state: string;\r\n    audioFile: string | null;\r\n    duration?: number;\r\n  }> = [];\r\n  \r\n  private sessionStats = {\r\n    totalQueued: 0,\r\n    totalStarted: 0,\r\n    totalCompleted: 0,\r\n    totalInterrupted: 0,\r\n    totalPlaybackTime: 0\r\n  };\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.setupAnalytics(channel);\r\n  }\r\n  \r\n  private setupAnalytics(channel: number): void {\r\n    // Track all lifecycle events\r\n    onQueueChange(channel, (snapshot) => {\r\n      if (snapshot.totalItems > 0) {\r\n        this.recordEvent('queued', snapshot.currentlyPlaying);\r\n        this.sessionStats.totalQueued++;\r\n      }\r\n    });\r\n    \r\n    onAudioStart(channel, (info) => {\r\n      this.recordEvent('started', info.fileName);\r\n      this.sessionStats.totalStarted++;\r\n    });\r\n    \r\n    onAudioComplete(channel, (info) => {\r\n      if (info.wasInterrupted) {\r\n        this.recordEvent('interrupted', info.fileName, info.playbackDuration);\r\n        this.sessionStats.totalInterrupted++;\r\n      } else {\r\n        this.recordEvent('completed', info.fileName, info.playbackDuration);\r\n        this.sessionStats.totalCompleted++;\r\n      }\r\n      \r\n      this.sessionStats.totalPlaybackTime += info.playbackDuration;\r\n    });\r\n  }\r\n  \r\n  private recordEvent(state: string, audioFile: string | null, duration?: number): void {\r\n    this.lifecycleEvents.push({\r\n      timestamp: Date.now(),\r\n      state,\r\n      audioFile,\r\n      duration\r\n    });\r\n    \r\n    console.log(`\ud83d\udcca Lifecycle Event: ${state} - ${audioFile || 'Unknown'}`);\r\n  }\r\n  \r\n  getLifecycleReport(): {\r\n    sessionDuration: number;\r\n    totalEvents: number;\r\n    completionRate: number;\r\n    averagePlaybackDuration: number;\r\n    sessionStats: typeof this.sessionStats;\r\n  } {\r\n    const sessionDuration = this.lifecycleEvents.length > 0 \r\n      ? Date.now() - this.lifecycleEvents[0].timestamp \r\n      : 0;\r\n    \r\n    const completionRate = this.sessionStats.totalStarted > 0 \r\n      ? this.sessionStats.totalCompleted / this.sessionStats.totalStarted \r\n      : 0;\r\n    \r\n    const averagePlaybackDuration = this.sessionStats.totalCompleted > 0 \r\n      ? this.sessionStats.totalPlaybackTime / this.sessionStats.totalCompleted \r\n      : 0;\r\n    \r\n    return {\r\n      sessionDuration,\r\n      totalEvents: this.lifecycleEvents.length,\r\n      completionRate,\r\n      averagePlaybackDuration,\r\n      sessionStats: { ...this.sessionStats }\r\n    };\r\n  }\r\n  \r\n  getEventTimeline(): Array<{\r\n    timestamp: number;\r\n    state: string;\r\n    audioFile: string | null;\r\n    duration?: number;\r\n  }> {\r\n    return [...this.lifecycleEvents];\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"error-handling-in-lifecycle",children:"Error Handling in Lifecycle"}),"\n",(0,o.jsx)(n.p,{children:"Handle errors and edge cases throughout the audio lifecycle:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"class AudioLifecycleErrorHandler {\r\n  private errorCount: number = 0;\r\n  private maxErrors: number = 5;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.setupErrorHandling(channel);\r\n  }\r\n  \r\n  private setupErrorHandling(channel: number): void {\r\n    // Monitor for lifecycle anomalies\r\n    \r\n    // Detect if audio fails to start\r\n    let expectingStart = false;\r\n    \r\n    onQueueChange(channel, (snapshot) => {\r\n      if (snapshot.totalItems > 0 && snapshot.currentlyPlaying) {\r\n        expectingStart = true;\r\n        \r\n        // Audio should start within reasonable time\r\n        setTimeout(() => {\r\n          if (expectingStart) {\r\n            this.handleStartTimeout(snapshot.currentlyPlaying);\r\n          }\r\n        }, 5000); // 5 second timeout\r\n      }\r\n    });\r\n    \r\n    onAudioStart(channel, () => {\r\n      expectingStart = false; // Audio started successfully\r\n    });\r\n    \r\n    // Detect if progress stops updating\r\n    let lastProgressTime = 0;\r\n    let progressStalled = false;\r\n    \r\n    onAudioProgress(channel, (info) => {\r\n      const now = Date.now();\r\n      \r\n      if (lastProgressTime > 0) {\r\n        const timeSinceLastProgress = now - lastProgressTime;\r\n        \r\n        if (timeSinceLastProgress > 2000 && !progressStalled) {\r\n          // Progress hasn't updated in 2 seconds\r\n          this.handleProgressStall(info.fileName);\r\n          progressStalled = true;\r\n        }\r\n      }\r\n      \r\n      lastProgressTime = now;\r\n      progressStalled = false;\r\n    });\r\n    \r\n    // Detect unexpected completions\r\n    onAudioComplete(channel, (info) => {\r\n      if (info.playbackDuration < 1000 && !info.wasInterrupted) {\r\n        // Audio completed very quickly, might be an error\r\n        this.handleSuspiciousCompletion(info);\r\n      }\r\n    });\r\n  }\r\n  \r\n  private handleStartTimeout(fileName: string | null): void {\r\n    this.errorCount++;\r\n    console.error(`\u274c Audio failed to start within timeout: ${fileName}`);\r\n    \r\n    if (this.errorCount >= this.maxErrors) {\r\n      this.handleCriticalError('Too many start failures');\r\n    }\r\n  }\r\n  \r\n  private handleProgressStall(fileName: string): void {\r\n    this.errorCount++;\r\n    console.error(`\u274c Audio progress stalled: ${fileName}`);\r\n    \r\n    // Maybe try to restart playback\r\n    this.attemptRecovery(fileName);\r\n  }\r\n  \r\n  private handleSuspiciousCompletion(info: AudioCompleteInfo): void {\r\n    this.errorCount++;\r\n    console.error(`\u274c Suspicious completion: ${info.fileName} (${info.playbackDuration}ms)`);\r\n    \r\n    // Maybe the file was corrupted or very short\r\n  }\r\n  \r\n  private attemptRecovery(fileName: string): void {\r\n    console.log(`\ud83d\udd04 Attempting recovery for ${fileName}`);\r\n    // Recovery logic - maybe restart the channel or skip to next\r\n  }\r\n  \r\n  private handleCriticalError(reason: string): void {\r\n    console.error(`\ud83d\udca5 Critical audio system error: ${reason}`);\r\n    // Maybe disable audio system or show error to user\r\n  }\r\n  \r\n  getErrorCount(): number {\r\n    return this.errorCount;\r\n  }\r\n  \r\n  resetErrors(): void {\r\n    this.errorCount = 0;\r\n    console.log('\u2728 Error count reset');\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"audio-loading-states-and-error-handling",children:"Audio Loading States and Error Handling"}),"\n",(0,o.jsx)(n.p,{children:"Track loading states and handle various error conditions:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"enum LoadingState {\r\n  IDLE = 'idle',\r\n  LOADING = 'loading', \r\n  LOADED = 'loaded',\r\n  ERROR = 'error',\r\n  TIMEOUT = 'timeout'\r\n}\r\n\r\nclass AudioLoadingTracker {\r\n  private loadingStates: Map<string, LoadingState> = new Map();\r\n  private loadingTimeouts: Map<string, NodeJS.Timeout> = new Map();\r\n  private readonly LOAD_TIMEOUT = 10000; // 10 seconds\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.setupLoadingTracking(channel);\r\n  }\r\n  \r\n  private setupLoadingTracking(channel: number): void {\r\n    // Track when audio is queued (starts loading)\r\n    onQueueChange(channel, (snapshot) => {\r\n      snapshot.items.forEach(item => {\r\n        if (!this.loadingStates.has(item.fileName)) {\r\n          this.setLoadingState(item.fileName, LoadingState.LOADING);\r\n          this.startLoadingTimeout(item.fileName);\r\n        }\r\n      });\r\n    });\r\n    \r\n    // Track successful loads\r\n    onAudioStart(channel, (info) => {\r\n      this.setLoadingState(info.fileName, LoadingState.LOADED);\r\n      this.clearLoadingTimeout(info.fileName);\r\n    });\r\n    \r\n    // Track completion (cleanup)\r\n    onAudioComplete(channel, (info) => {\r\n      // Clean up after a delay to allow for UI updates\r\n      setTimeout(() => {\r\n        this.cleanupLoadingState(info.fileName);\r\n      }, 1000);\r\n    });\r\n  }\r\n  \r\n  private setLoadingState(fileName: string, state: LoadingState): void {\r\n    const oldState = this.loadingStates.get(fileName);\r\n    this.loadingStates.set(fileName, state);\r\n    \r\n    console.log(`\ud83d\udcc2 Loading: ${fileName} - ${oldState || 'UNKNOWN'} \u2192 ${state}`);\r\n    \r\n    // Trigger UI updates\r\n    this.notifyLoadingStateChange(fileName, state);\r\n  }\r\n  \r\n  private startLoadingTimeout(fileName: string): void {\r\n    const timeout = setTimeout(() => {\r\n      const currentState = this.loadingStates.get(fileName);\r\n      if (currentState === LoadingState.LOADING) {\r\n        this.setLoadingState(fileName, LoadingState.TIMEOUT);\r\n        this.handleLoadingTimeout(fileName);\r\n      }\r\n    }, this.LOAD_TIMEOUT);\r\n    \r\n    this.loadingTimeouts.set(fileName, timeout);\r\n  }\r\n  \r\n  private clearLoadingTimeout(fileName: string): void {\r\n    const timeout = this.loadingTimeouts.get(fileName);\r\n    if (timeout) {\r\n      clearTimeout(timeout);\r\n      this.loadingTimeouts.delete(fileName);\r\n    }\r\n  }\r\n  \r\n  private handleLoadingTimeout(fileName: string): void {\r\n    console.error(`\u23f1\ufe0f Loading timeout for: ${fileName}`);\r\n    // Could show user notification, try alternate sources, etc.\r\n  }\r\n  \r\n  private cleanupLoadingState(fileName: string): void {\r\n    this.loadingStates.delete(fileName);\r\n    this.clearLoadingTimeout(fileName);\r\n  }\r\n  \r\n  private notifyLoadingStateChange(fileName: string, state: LoadingState): void {\r\n    // Update UI based on loading state\r\n    const event = new CustomEvent('audioLoadingStateChange', {\r\n      detail: { fileName, state }\r\n    });\r\n    document.dispatchEvent(event);\r\n  }\r\n  \r\n  // Public API\r\n  getLoadingState(fileName: string): LoadingState {\r\n    return this.loadingStates.get(fileName) || LoadingState.IDLE;\r\n  }\r\n  \r\n  getAllLoadingStates(): Map<string, LoadingState> {\r\n    return new Map(this.loadingStates);\r\n  }\r\n  \r\n  isLoading(fileName: string): boolean {\r\n    return this.getLoadingState(fileName) === LoadingState.LOADING;\r\n  }\r\n  \r\n  hasError(fileName: string): boolean {\r\n    const state = this.getLoadingState(fileName);\r\n    return state === LoadingState.ERROR || state === LoadingState.TIMEOUT;\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"browser-compatibility-and-network-error-handling",children:"Browser Compatibility and Network Error Handling"}),"\n",(0,o.jsx)(n.p,{children:"Handle browser-specific issues and network problems:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"class AudioCompatibilityHandler {\r\n  private supportedFormats: string[] = [];\r\n  private networkErrors: number = 0;\r\n  private readonly MAX_NETWORK_ERRORS = 3;\r\n  \r\n  constructor() {\r\n    this.detectSupportedFormats();\r\n    this.setupNetworkErrorHandling();\r\n  }\r\n  \r\n  private detectSupportedFormats(): void {\r\n    const audio = new Audio();\r\n    const formats = [\r\n      { ext: 'mp3', type: 'audio/mpeg' },\r\n      { ext: 'wav', type: 'audio/wav' },\r\n      { ext: 'ogg', type: 'audio/ogg' },\r\n      { ext: 'm4a', type: 'audio/mp4' },\r\n      { ext: 'webm', type: 'audio/webm' }\r\n    ];\r\n    \r\n    this.supportedFormats = formats\r\n      .filter(format => audio.canPlayType(format.type) !== '')\r\n      .map(format => format.ext);\r\n    \r\n    console.log('\ud83c\udfb5 Supported audio formats:', this.supportedFormats);\r\n  }\r\n  \r\n  private setupNetworkErrorHandling(): void {\r\n    // Monitor for network-related failures\r\n    let consecutiveFailures = 0;\r\n    \r\n    onQueueChange(0, (snapshot) => {\r\n      // Reset failure count on successful queue changes\r\n      if (snapshot.totalItems > 0) {\r\n        consecutiveFailures = 0;\r\n      }\r\n    });\r\n    \r\n    // This would need to be implemented via actual error detection\r\n    // since onAudioError doesn't exist yet\r\n    this.simulateNetworkErrorDetection();\r\n  }\r\n  \r\n  private simulateNetworkErrorDetection(): void {\r\n    // This is a placeholder - in reality you'd detect network errors\r\n    // through various means like monitoring for stalled progress,\r\n    // failed audio starts, etc.\r\n    \r\n    let lastSuccessfulStart = Date.now();\r\n    \r\n    onAudioStart(0, () => {\r\n      lastSuccessfulStart = Date.now();\r\n      this.networkErrors = 0; // Reset on success\r\n    });\r\n    \r\n    // Check for potential network issues\r\n    setInterval(() => {\r\n      const timeSinceLastSuccess = Date.now() - lastSuccessfulStart;\r\n      \r\n      // If no successful starts in a while and we have queued items\r\n      if (timeSinceLastSuccess > 30000) { // 30 seconds\r\n        const snapshot = getQueueSnapshot(0);\r\n        if (snapshot.totalItems > 0 && !snapshot.currentlyPlaying) {\r\n          this.handlePotentialNetworkIssue();\r\n        }\r\n      }\r\n    }, 10000); // Check every 10 seconds\r\n  }\r\n  \r\n  private handlePotentialNetworkIssue(): void {\r\n    this.networkErrors++;\r\n    console.warn(`\ud83c\udf10 Potential network issue detected (${this.networkErrors}/${this.MAX_NETWORK_ERRORS})`);\r\n    \r\n    if (this.networkErrors >= this.MAX_NETWORK_ERRORS) {\r\n      this.handleNetworkFailure();\r\n    }\r\n  }\r\n  \r\n  private handleNetworkFailure(): void {\r\n    console.error('\ud83d\udeab Network failure detected - audio system degraded');\r\n    \r\n    // Show user notification\r\n    this.showNetworkErrorNotification();\r\n    \r\n    // Maybe switch to lower quality audio or cached content\r\n    this.enableOfflineMode();\r\n  }\r\n  \r\n  private showNetworkErrorNotification(): void {\r\n    const notification = document.createElement('div');\r\n    notification.className = 'audio-network-error';\r\n    notification.innerHTML = `\r\n      <div class=\"error-message\">\r\n        <span class=\"error-icon\">\u26a0\ufe0f</span>\r\n        <span>Network issues detected. Audio quality may be reduced.</span>\r\n        <button onclick=\"this.parentElement.parentElement.remove()\">\u2716\ufe0f</button>\r\n      </div>\r\n    `;\r\n    document.body.appendChild(notification);\r\n  }\r\n  \r\n  private enableOfflineMode(): void {\r\n    console.log('\ud83d\udd04 Switching to offline mode...');\r\n    // Implementation would depend on your caching strategy\r\n  }\r\n  \r\n  // Public API\r\n  isFormatSupported(fileName: string): boolean {\r\n    const extension = fileName.split('.').pop()?.toLowerCase() || '';\r\n    return this.supportedFormats.includes(extension);\r\n  }\r\n  \r\n  getSupportedFormats(): string[] {\r\n    return [...this.supportedFormats];\r\n  }\r\n  \r\n  getNetworkErrorCount(): number {\r\n    return this.networkErrors;\r\n  }\r\n  \r\n  resetNetworkErrors(): void {\r\n    this.networkErrors = 0;\r\n    console.log('\u2705 Network error count reset');\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"performance-monitoring-and-memory-management",children:"Performance Monitoring and Memory Management"}),"\n",(0,o.jsx)(n.p,{children:"Monitor performance and manage memory usage:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"class AudioPerformanceMonitor {\r\n  private memoryUsage: number[] = [];\r\n  private performanceMetrics: Map<string, number> = new Map();\r\n  private readonly MAX_MEMORY_SAMPLES = 100;\r\n  \r\n  constructor() {\r\n    this.setupPerformanceMonitoring();\r\n  }\r\n  \r\n  private setupPerformanceMonitoring(): void {\r\n    // Monitor memory usage\r\n    if ('memory' in performance) {\r\n      setInterval(() => {\r\n        this.recordMemoryUsage();\r\n      }, 5000); // Every 5 seconds\r\n    }\r\n    \r\n    // Monitor audio performance\r\n    onAudioStart(0, (info) => {\r\n      this.recordPerformanceMetric('audio_start_time', Date.now());\r\n    });\r\n    \r\n    onAudioComplete(0, (info) => {\r\n      const startTime = this.performanceMetrics.get('audio_start_time');\r\n      if (startTime) {\r\n        const loadTime = Date.now() - startTime;\r\n        this.recordPerformanceMetric('audio_load_duration', loadTime);\r\n        console.log(`\ud83d\udcca Audio load time: ${loadTime}ms for ${info.fileName}`);\r\n      }\r\n    });\r\n  }\r\n  \r\n  private recordMemoryUsage(): void {\r\n    if ('memory' in performance) {\r\n      const memory = (performance as any).memory;\r\n      const usedMB = memory.usedJSHeapSize / (1024 * 1024);\r\n      \r\n      this.memoryUsage.push(usedMB);\r\n      \r\n      // Keep only recent samples\r\n      if (this.memoryUsage.length > this.MAX_MEMORY_SAMPLES) {\r\n        this.memoryUsage.shift();\r\n      }\r\n      \r\n      // Check for memory leaks\r\n      this.checkForMemoryLeaks(usedMB);\r\n    }\r\n  }\r\n  \r\n  private checkForMemoryLeaks(currentUsage: number): void {\r\n    if (this.memoryUsage.length < 10) return;\r\n    \r\n    const recentAverage = this.memoryUsage.slice(-10).reduce((a, b) => a + b) / 10;\r\n    const oldAverage = this.memoryUsage.slice(0, 10).reduce((a, b) => a + b) / 10;\r\n    \r\n    const growthRate = (recentAverage - oldAverage) / oldAverage;\r\n    \r\n    if (growthRate > 0.5) { // 50% increase\r\n      console.warn(`\ud83e\udde0 Potential memory leak detected: ${growthRate * 100}% increase`);\r\n      this.handleMemoryWarning();\r\n    }\r\n  }\r\n  \r\n  private handleMemoryWarning(): void {\r\n    console.log('\ud83d\udd04 Attempting memory cleanup...');\r\n    \r\n    // Force garbage collection if available\r\n    if ('gc' in window && typeof (window as any).gc === 'function') {\r\n      (window as any).gc();\r\n    }\r\n    \r\n    // Clear old performance metrics\r\n    this.performanceMetrics.clear();\r\n    \r\n    // Could also stop non-essential audio processing\r\n  }\r\n  \r\n  private recordPerformanceMetric(name: string, value: number): void {\r\n    this.performanceMetrics.set(name, value);\r\n  }\r\n  \r\n  // Public API\r\n  getMemoryUsage(): number[] {\r\n    return [...this.memoryUsage];\r\n  }\r\n  \r\n  getCurrentMemoryUsage(): number {\r\n    if ('memory' in performance) {\r\n      const memory = (performance as any).memory;\r\n      return memory.usedJSHeapSize / (1024 * 1024); // MB\r\n    }\r\n    return 0;\r\n  }\r\n  \r\n  getPerformanceReport(): object {\r\n    const avgMemory = this.memoryUsage.length > 0 \r\n      ? this.memoryUsage.reduce((a, b) => a + b) / this.memoryUsage.length \r\n      : 0;\r\n    \r\n    return {\r\n      averageMemoryUsage: avgMemory,\r\n      currentMemoryUsage: this.getCurrentMemoryUsage(),\r\n      memoryTrend: this.calculateMemoryTrend(),\r\n      performanceMetrics: Object.fromEntries(this.performanceMetrics)\r\n    };\r\n  }\r\n  \r\n  private calculateMemoryTrend(): 'increasing' | 'decreasing' | 'stable' {\r\n    if (this.memoryUsage.length < 2) return 'stable';\r\n    \r\n    const recent = this.memoryUsage.slice(-5);\r\n    const older = this.memoryUsage.slice(-10, -5);\r\n    \r\n    if (recent.length === 0 || older.length === 0) return 'stable';\r\n    \r\n    const recentAvg = recent.reduce((a, b) => a + b) / recent.length;\r\n    const olderAvg = older.reduce((a, b) => a + b) / older.length;\r\n    \r\n    const threshold = 0.05; // 5% threshold\r\n    \r\n    if (recentAvg > olderAvg * (1 + threshold)) return 'increasing';\r\n    if (recentAvg < olderAvg * (1 - threshold)) return 'decreasing';\r\n    return 'stable';\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"complete-lifecycle-manager",children:"Complete Lifecycle Manager"}),"\n",(0,o.jsx)(n.p,{children:"Combine all lifecycle management into one comprehensive system:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-typescript",children:"class AudioLifecycleManager {\r\n  private errorHandler: AudioLifecycleErrorHandler;\r\n  private loadingTracker: AudioLoadingTracker;\r\n  private compatibilityHandler: AudioCompatibilityHandler;\r\n  private performanceMonitor: AudioPerformanceMonitor;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.errorHandler = new AudioLifecycleErrorHandler(channel);\r\n    this.loadingTracker = new AudioLoadingTracker(channel);\r\n    this.compatibilityHandler = new AudioCompatibilityHandler();\r\n    this.performanceMonitor = new AudioPerformanceMonitor();\r\n    \r\n    this.setupUnifiedReporting();\r\n  }\r\n  \r\n  private setupUnifiedReporting(): void {\r\n    // Generate comprehensive reports periodically\r\n    setInterval(() => {\r\n      this.generateHealthReport();\r\n    }, 30000); // Every 30 seconds\r\n  }\r\n  \r\n  private generateHealthReport(): void {\r\n    const report = {\r\n      timestamp: new Date().toISOString(),\r\n      errors: {\r\n        count: this.errorHandler.getErrorCount(),\r\n        networkErrors: this.compatibilityHandler.getNetworkErrorCount()\r\n      },\r\n      loading: {\r\n        activeStates: Array.from(this.loadingTracker.getAllLoadingStates().entries())\r\n      },\r\n      compatibility: {\r\n        supportedFormats: this.compatibilityHandler.getSupportedFormats()\r\n      },\r\n      performance: this.performanceMonitor.getPerformanceReport()\r\n    };\r\n    \r\n    console.log('\ud83d\udccb Audio System Health Report:', report);\r\n    \r\n    // Could send to analytics or monitoring service\r\n    this.sendHealthReport(report);\r\n  }\r\n  \r\n  private sendHealthReport(report: object): void {\r\n    // Placeholder for sending reports to monitoring service\r\n    // In a real application, you might send this to your analytics platform\r\n  }\r\n  \r\n  // Public API for manual intervention\r\n  resetErrorCounts(): void {\r\n    this.errorHandler.resetErrors();\r\n    this.compatibilityHandler.resetNetworkErrors();\r\n    console.log('\ud83d\udd04 All error counts reset');\r\n  }\r\n  \r\n  getSystemHealth(): 'healthy' | 'warning' | 'critical' {\r\n    const errorCount = this.errorHandler.getErrorCount();\r\n    const networkErrors = this.compatibilityHandler.getNetworkErrorCount();\r\n    const memoryTrend = this.performanceMonitor.getPerformanceReport() as any;\r\n    \r\n    if (errorCount >= 5 || networkErrors >= 3 || memoryTrend.memoryTrend === 'increasing') {\r\n      return 'critical';\r\n    } else if (errorCount >= 2 || networkErrors >= 1) {\r\n      return 'warning';  \r\n    } else {\r\n      return 'healthy';\r\n    }\r\n  }\r\n  \r\n  attemptSystemRecovery(): void {\r\n    console.log('\ud83d\ude91 Attempting system recovery...');\r\n    \r\n    // Reset error counts\r\n    this.resetErrorCounts();\r\n    \r\n    // Clear any stuck audio\r\n    stopAllAudioInChannel(0);\r\n    \r\n    // Force memory cleanup\r\n    if ('gc' in window && typeof (window as any).gc === 'function') {\r\n      (window as any).gc();\r\n    }\r\n    \r\n    console.log('\u2705 System recovery completed');\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"Now that you understand the complete audio lifecycle, explore:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"/audio-queue-docs/core-concepts/performance-memory",children:"Performance & Memory"})})," - Optimization strategies for the entire lifecycle"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"../api-reference/queue-management",children:"API Reference"})})," - Detailed function documentation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"../getting-started/basic-usage",children:"Examples"})})," - Real-world lifecycle management patterns"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.a,{href:"../advanced/volume-ducking",children:"Advanced Features"})})," - Complex lifecycle scenarios"]}),"\n"]})]})}function u(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>s});var t=r(6540);const o={},i=t.createContext(o);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);