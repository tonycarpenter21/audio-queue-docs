"use strict";(self.webpackChunkaudio_queue_docs=self.webpackChunkaudio_queue_docs||[]).push([[204],{1504:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>u,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"core-concepts/queue-system","title":"Queue System","description":"Understanding how audio queuing works within channels and how to manage playback order and timing.","source":"@site/docs/core-concepts/queue-system.md","sourceDirName":"core-concepts","slug":"/core-concepts/queue-system","permalink":"/audio-queue-docs/core-concepts/queue-system","draft":false,"unlisted":false,"editUrl":"https://github.com/tonycarpenter21/audio-queue-docs/tree/main/docs/core-concepts/queue-system.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Audio Channels","permalink":"/audio-queue-docs/core-concepts/audio-channels"},"next":{"title":"Event System","permalink":"/audio-queue-docs/core-concepts/event-system"}}');var a=r(4848),i=r(8453);const s={},u="Queue System",o={},l=[{value:"What is the Queue System?",id:"what-is-the-queue-system",level:2},{value:"Queue Behavior",id:"queue-behavior",level:2},{value:"Standard Queuing",id:"standard-queuing",level:3},{value:"Priority Queuing",id:"priority-queuing",level:3},{value:"Mixed Queuing Patterns",id:"mixed-queuing-patterns",level:3},{value:"Queue States and Information",id:"queue-states-and-information",level:2},{value:"Queue Snapshots",id:"queue-snapshots",level:3},{value:"Real-time Queue Monitoring",id:"real-time-queue-monitoring",level:3},{value:"Queue Management Patterns",id:"queue-management-patterns",level:2},{value:"Playlist Management",id:"playlist-management",level:3},{value:"Dynamic Content Insertion",id:"dynamic-content-insertion",level:3},{value:"Smart Queue Management",id:"smart-queue-management",level:3},{value:"Queue Timing and Coordination",id:"queue-timing-and-coordination",level:2},{value:"Preloading and Timing",id:"preloading-and-timing",level:3},{value:"Cross-Channel Synchronization",id:"cross-channel-synchronization",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Efficient Queue Operations",id:"efficient-queue-operations",level:3},{value:"Common Queue Patterns",id:"common-queue-patterns",level:2},{value:"Gaming Audio Queues",id:"gaming-audio-queues",level:3},{value:"Podcast Queue Management",id:"podcast-queue-management",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"queue-system",children:"Queue System"})}),"\n",(0,a.jsx)(n.p,{children:"Understanding how audio queuing works within channels and how to manage playback order and timing."}),"\n",(0,a.jsx)(n.h2,{id:"what-is-the-queue-system",children:"What is the Queue System?"}),"\n",(0,a.jsxs)(n.p,{children:["Each audio channel maintains its own ",(0,a.jsx)(n.strong,{children:"First-In-First-Out (FIFO)"})," queue that automatically manages audio playback order. When you queue audio, it gets added to the end of the channel's queue and plays when it's turn comes."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio, queueAudioPriority, getQueueSnapshot } from 'audio-channel-queue';\r\n\r\n// Queue multiple audio files - they play in order (using default channel 0)\r\nawait queueAudio('./audio/track1.mp3');\r\nawait queueAudio('./audio/track2.mp3');\r\nawait queueAudio('./audio/track3.mp3');\r\n\r\n// Check the queue\r\nconst snapshot = getQueueSnapshot();\r\nconsole.log(`Queue has ${snapshot.totalItems} items`);\r\n// Will play: track1 \u2192 track2 \u2192 track3\n"})}),"\n",(0,a.jsx)(n.h2,{id:"queue-behavior",children:"Queue Behavior"}),"\n",(0,a.jsx)(n.h3,{id:"standard-queuing",children:"Standard Queuing"}),"\n",(0,a.jsxs)(n.p,{children:["With ",(0,a.jsx)(n.code,{children:"queueAudio()"}),", files are added to the end of the queue:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio, onAudioStart } from 'audio-channel-queue';\r\n\r\n// Setup logging to see the order\r\nonAudioStart(0, (info) => {\r\n  console.log(`Now playing: ${info.fileName}`);\r\n});\r\n\r\n// Queue several tracks (using default channel 0)\r\nawait queueAudio('./music/intro.mp3');        // Plays immediately\r\nawait queueAudio('./music/main-theme.mp3');   // Plays after intro\r\nawait queueAudio('./music/outro.mp3');        // Plays after main-theme\r\n\r\n// Order: intro \u2192 main-theme \u2192 outro\n"})}),"\n",(0,a.jsx)(n.h3,{id:"priority-queuing",children:"Priority Queuing"}),"\n",(0,a.jsxs)(n.p,{children:["With ",(0,a.jsx)(n.code,{children:"queueAudioPriority()"}),", files interrupt current playback and jump to the front:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio, queueAudioPriority } from 'audio-channel-queue';\r\n\r\n// Start with background music (using default channel 0)\r\nawait queueAudio('./music/background.mp3');\r\n\r\n// Urgent announcement interrupts immediately\r\nawait queueAudioPriority('./voice/emergency-alert.mp3');\r\n\r\n// Background music will resume after the alert\n"})}),"\n",(0,a.jsx)(n.h3,{id:"mixed-queuing-patterns",children:"Mixed Queuing Patterns"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"// Complex queuing scenario\r\nasync function demonstrateQueueing(): Promise<void> {\r\n  // 1. Start background music (using default channel 0)\r\n  await queueAudio('./music/calm-background.mp3', 0, { loop: true });\r\n  \r\n  // 2. Queue some planned content\r\n  await queueAudio('./voice/welcome.mp3');\r\n  await queueAudio('./voice/instructions.mp3');\r\n  \r\n  // 3. Emergency interruption\r\n  await queueAudioPriority('./alerts/urgent.mp3');\r\n  \r\n  // 4. More content after emergency\r\n  await queueAudio('./voice/continue.mp3');\r\n  \r\n  // Final order: urgent \u2192 welcome \u2192 instructions \u2192 continue\r\n  // (background music was stopped by the first priority call)\r\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"queue-states-and-information",children:"Queue States and Information"}),"\n",(0,a.jsx)(n.h3,{id:"queue-snapshots",children:"Queue Snapshots"}),"\n",(0,a.jsx)(n.p,{children:"Get complete information about a channel's queue:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import { getQueueSnapshot, QueueSnapshot, QueueItem } from 'audio-channel-queue';\r\n\r\nfunction analyzeQueue(channel: number): void {\r\n  const snapshot: QueueSnapshot = channel === 0 ? getQueueSnapshot() : getQueueSnapshot(channel);\r\n  \r\n  console.log(`Channel ${channel} Queue Analysis:`);\r\n  console.log(`- Total items: ${snapshot.totalItems}`);\r\n  console.log(`- Currently playing: ${snapshot.currentlyPlaying || 'Nothing'}`);\r\n  console.log(`- Channel active: ${snapshot.isChannelActive}`);\r\n  \r\n  if (snapshot.items.length > 0) {\r\n    console.log('\\nQueue Items:');\r\n    snapshot.items.forEach((item: QueueItem, index: number) => {\r\n      const status = item.isCurrentlyPlaying ? '\ud83d\udd0a Playing' : '\u23f3 Queued';\r\n      const duration = Math.round(item.duration / 1000);\r\n      console.log(`  ${item.position}. ${status} - ${item.fileName} (${duration}s)`);\r\n    });\r\n  }\r\n}\r\n\r\n// Use it - examples with both default and explicit channel\r\nanalyzeQueue(0);  // Can use default: getQueueSnapshot()\r\nanalyzeQueue(1);  // Must be explicit: getQueueSnapshot(1)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"real-time-queue-monitoring",children:"Real-time Queue Monitoring"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"import { onQueueChange } from 'audio-channel-queue';\r\n\r\nclass QueueMonitor {\r\n  setupQueueTracking(channel: number): void {\r\n    onQueueChange(channel, (snapshot) => {\r\n      console.log(`Queue changed on channel ${channel}:`);\r\n      console.log(`- Items: ${snapshot.totalItems}`);\r\n      console.log(`- Playing: ${snapshot.currentlyPlaying}`);\r\n      \r\n      // React to queue events\r\n      if (snapshot.totalItems === 0) {\r\n        this.onQueueEmpty(channel);\r\n      } else if (snapshot.totalItems > 10) {\r\n        this.onQueueOverloaded(channel);\r\n      }\r\n    });\r\n  }\r\n  \r\n  onQueueEmpty(channel: number): void {\r\n    console.log(`Channel ${channel} queue is empty - maybe start background music?`);\r\n  }\r\n  \r\n  onQueueOverloaded(channel: number): void {\r\n    console.log(`Channel ${channel} queue is getting long - consider optimization`);\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"queue-management-patterns",children:"Queue Management Patterns"}),"\n",(0,a.jsx)(n.h3,{id:"playlist-management",children:"Playlist Management"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class PlaylistManager {\r\n  private playlist: string[] = [];\r\n  private currentIndex: number = 0;\r\n  private channel: number = 0;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.channel = channel;\r\n    this.setupEventHandlers();\r\n  }\r\n  \r\n  loadPlaylist(audioFiles: string[]): void {\r\n    this.playlist = [...audioFiles];\r\n    this.currentIndex = 0;\r\n  }\r\n  \r\n  async startPlaylist(): Promise<void> {\r\n    if (this.playlist.length === 0) return;\r\n    \r\n    // Queue all tracks\r\n    for (const track of this.playlist) {\r\n      await queueAudio(track, this.channel);\r\n    }\r\n  }\r\n  \r\n  async skipToNext(): Promise<void> {\r\n    // Stop current and play next\r\n    stopCurrentAudioInChannel(this.channel);\r\n    \r\n    this.currentIndex++;\r\n    if (this.currentIndex < this.playlist.length) {\r\n      await queueAudioPriority(this.playlist[this.currentIndex], this.channel);\r\n    }\r\n  }\r\n  \r\n  async skipToPrevious(): Promise<void> {\r\n    this.currentIndex = Math.max(0, this.currentIndex - 1);\r\n    stopCurrentAudioInChannel(this.channel);\r\n    await queueAudioPriority(this.playlist[this.currentIndex], this.channel);\r\n  }\r\n  \r\n  private setupEventHandlers(): void {\r\n    onAudioComplete(this.channel, (info) => {\r\n      console.log(`Completed: ${info.fileName}`);\r\n      \r\n      // Auto-advance playlist\r\n      if (info.remainingInQueue === 0 && this.currentIndex < this.playlist.length - 1) {\r\n        this.skipToNext();\r\n      }\r\n    });\r\n  }\r\n}\r\n\r\n// Usage\r\nconst musicPlayer = new PlaylistManager(0);\r\nmusicPlayer.loadPlaylist([\r\n  './music/track1.mp3',\r\n  './music/track2.mp3', \r\n  './music/track3.mp3'\r\n]);\r\nawait musicPlayer.startPlaylist();\n"})}),"\n",(0,a.jsx)(n.h3,{id:"dynamic-content-insertion",children:"Dynamic Content Insertion"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class DynamicContentManager {\r\n  private baseChannel: number = 0;\r\n  private adChannel: number = 1;\r\n  \r\n  async startMainContent(contentUrl: string): Promise<void> {\r\n    await queueAudio(contentUrl, this.baseChannel);\r\n  }\r\n  \r\n  async insertAd(adUrl: string, returnToContent: boolean = true): Promise<void> {\r\n    // Pause main content\r\n    pauseChannel(this.baseChannel);\r\n    \r\n    // Play ad on separate channel\r\n    await queueAudioPriority(adUrl, this.adChannel);\r\n    \r\n    if (returnToContent) {\r\n      // Resume main content when ad finishes\r\n      onAudioComplete(this.adChannel, () => {\r\n        resumeChannel(this.baseChannel);\r\n      });\r\n    }\r\n  }\r\n  \r\n  async insertBreakingNews(newsUrl: string): Promise<void> {\r\n    // Interrupt everything with priority news\r\n    await queueAudioPriority(newsUrl, this.baseChannel);\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"smart-queue-management",children:"Smart Queue Management"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class SmartQueueManager {\r\n  private readonly maxQueueSize: number = 10;\r\n  private readonly channel: number;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.channel = channel;\r\n  }\r\n  \r\n  async smartQueue(audioUrl: string, priority: boolean = false): Promise<boolean> {\r\n    const snapshot = this.channel === 0 ? getQueueSnapshot() : getQueueSnapshot(this.channel);\r\n    \r\n    // Check queue capacity\r\n    if (snapshot.totalItems >= this.maxQueueSize) {\r\n      console.warn(`Queue full on channel ${this.channel}, rejecting: ${audioUrl}`);\r\n      return false;\r\n    }\r\n    \r\n    try {\r\n      if (priority) {\r\n        if (this.channel === 0) {\r\n          await queueAudioPriority(audioUrl);\r\n        } else {\r\n          await queueAudioPriority(audioUrl, this.channel);\r\n        }\r\n      } else {\r\n        if (this.channel === 0) {\r\n          await queueAudio(audioUrl);\r\n        } else {\r\n          await queueAudio(audioUrl, this.channel);\r\n        }\r\n      }\r\n      return true;\r\n    } catch (error) {\r\n      console.error(`Failed to queue ${audioUrl}:`, error);\r\n      return false;\r\n    }\r\n  }\r\n  \r\n  getQueueHealth(): { \r\n    utilization: number; \r\n    isHealthy: boolean; \r\n    recommendation: string \r\n  } {\r\n    const snapshot = this.channel === 0 ? getQueueSnapshot() : getQueueSnapshot(this.channel);\r\n    const utilization = snapshot.totalItems / this.maxQueueSize;\r\n    \r\n    let recommendation: string;\r\n    let isHealthy: boolean = true;\r\n    \r\n    if (utilization < 0.3) {\r\n      recommendation = 'Queue is light, good for responsiveness';\r\n    } else if (utilization < 0.7) {\r\n      recommendation = 'Queue utilization is optimal';\r\n    } else if (utilization < 0.9) {\r\n      recommendation = 'Queue is getting full, consider reducing load';\r\n      isHealthy = false;\r\n    } else {\r\n      recommendation = 'Queue is nearly full, high risk of rejections';\r\n      isHealthy = false;\r\n    }\r\n    \r\n    return { utilization, isHealthy, recommendation };\r\n  }\r\n  \r\n  async clearOldItems(): Promise<number> {\r\n    // This is conceptual - the package handles queue management internally\r\n    // But you can track and make decisions based on queue state\r\n    const snapshot = this.channel === 0 ? getQueueSnapshot() : getQueueSnapshot(this.channel);\r\n    \r\n    if (snapshot.totalItems > 7) {\r\n      console.log(`Queue has ${snapshot.totalItems} items, consider stopping current audio`);\r\n      if (this.channel === 0) {\r\n        stopCurrentAudioInChannel();\r\n      } else {\r\n        stopCurrentAudioInChannel(this.channel);\r\n      }\r\n      return snapshot.totalItems;\r\n    }\r\n    \r\n    return 0;\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"queue-timing-and-coordination",children:"Queue Timing and Coordination"}),"\n",(0,a.jsx)(n.h3,{id:"preloading-and-timing",children:"Preloading and Timing"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class TimedQueueManager {\r\n  async scheduleAudio(audioUrl: string, delayMs: number, channel: number = 0): Promise<void> {\r\n    setTimeout(async () => {\r\n      await queueAudio(audioUrl, channel);\r\n      console.log(`Scheduled audio started: ${audioUrl}`);\r\n    }, delayMs);\r\n  }\r\n  \r\n  async createTightPlaylist(tracks: string[], channel: number = 0): Promise<void> {\r\n    // Queue first track immediately\r\n    if (tracks.length > 0) {\r\n      await queueAudio(tracks[0], channel);\r\n    }\r\n    \r\n    // Queue remaining tracks\r\n    for (let i = 1; i < tracks.length; i++) {\r\n      await queueAudio(tracks[i], channel);\r\n    }\r\n    \r\n    console.log(`Queued ${tracks.length} tracks for seamless playback`);\r\n  }\r\n  \r\n  async createGappedPlaylist(tracks: string[], gapMs: number, channel: number = 0): Promise<void> {\r\n    // This is conceptual - you'd need additional logic for gaps\r\n    // The queue system plays tracks seamlessly by design\r\n    \r\n    for (let i = 0; i < tracks.length; i++) {\r\n      if (i === 0) {\r\n        await queueAudio(tracks[i], channel);\r\n      } else {\r\n        // For gaps, you might queue silence or use timed scheduling\r\n        setTimeout(async () => {\r\n          await queueAudio(tracks[i], channel);\r\n        }, i * gapMs);\r\n      }\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"cross-channel-synchronization",children:"Cross-Channel Synchronization"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class SynchronizedQueueManager {\r\n  async syncChannelPlayback(channel1: number, channel2: number): Promise<void> {\r\n    // Start audio on both channels simultaneously\r\n    const promises = [\r\n      queueAudio('./audio/left-channel.mp3', channel1),\r\n      queueAudio('./audio/right-channel.mp3', channel2)\r\n    ];\r\n    \r\n    await Promise.all(promises);\r\n    console.log('Synchronized playback started on both channels');\r\n  }\r\n  \r\n  async createCallAndResponse(callTrack: string, responseTrack: string): Promise<void> {\r\n    // Play call on channel 0\r\n    await queueAudio(callTrack, 0);\r\n    \r\n    // When call finishes, play response on channel 1\r\n    onAudioComplete(0, async () => {\r\n      await queueAudio(responseTrack, 1);\r\n    });\r\n  }\r\n  \r\n  async orchestrateMultiChannelSequence(): Promise<void> {\r\n    // Complex multi-channel coordination\r\n    \r\n    // Start background music\r\n    await queueAudio('./music/background.mp3', 0, { loop: true, volume: 0.3 });\r\n    \r\n    // Layer in sound effects\r\n    setTimeout(() => queueAudio('./sfx/wind.mp3', 1), 2000);\r\n    setTimeout(() => queueAudio('./sfx/birds.mp3', 2), 4000);\r\n    \r\n    // Add narration that ducks other audio\r\n    setTimeout(async () => {\r\n      // Duck background channels\r\n      setChannelVolume(0, 0.1);\r\n      setChannelVolume(1, 0.2);\r\n      setChannelVolume(2, 0.2);\r\n      \r\n      // Play narration\r\n      await queueAudio('./voice/narration.mp3', 3);\r\n      \r\n      // Restore volumes when narration ends\r\n      onAudioComplete(3, () => {\r\n        setChannelVolume(0, 0.3);\r\n        setChannelVolume(1, 1.0);\r\n        setChannelVolume(2, 1.0);\r\n      });\r\n    }, 6000);\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,a.jsx)(n.h3,{id:"efficient-queue-operations",children:"Efficient Queue Operations"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class EfficientQueueManager {\r\n  private queueCache: Map<number, QueueSnapshot> = new Map();\r\n  private cacheTimeout: number = 1000; // 1 second cache\r\n  \r\n  getCachedQueueSnapshot(channel: number): QueueSnapshot {\r\n    const cached = this.queueCache.get(channel);\r\n    if (cached) {\r\n      return cached;\r\n    }\r\n    \r\n    const snapshot = getQueueSnapshot(channel);\r\n    this.queueCache.set(channel, snapshot);\r\n    \r\n    // Clear cache after timeout\r\n    setTimeout(() => {\r\n      this.queueCache.delete(channel);\r\n    }, this.cacheTimeout);\r\n    \r\n    return snapshot;\r\n  }\r\n  \r\n  async batchQueueAudio(audioFiles: string[], channel: number): Promise<void> {\r\n    // Queue multiple files efficiently\r\n    const promises = audioFiles.map(file => queueAudio(file, channel));\r\n    await Promise.all(promises);\r\n    console.log(`Batch queued ${audioFiles.length} files on channel ${channel}`);\r\n  }\r\n  \r\n  optimizeQueueSize(channel: number, maxItems: number = 5): void {\r\n    const snapshot = this.getCachedQueueSnapshot(channel);\r\n    \r\n    if (snapshot.totalItems > maxItems) {\r\n      console.warn(`Channel ${channel} queue has ${snapshot.totalItems} items, above optimal size of ${maxItems}`);\r\n      // Consider stopping current audio to clear queue\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"common-queue-patterns",children:"Common Queue Patterns"}),"\n",(0,a.jsx)(n.h3,{id:"gaming-audio-queues",children:"Gaming Audio Queues"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class GameAudioQueue {\r\n  private musicChannel: number = 0;\r\n  private sfxChannel: number = 1;\r\n  private voiceChannel: number = 2;\r\n  \r\n  async playGameSequence(): Promise<void> {\r\n    // Background music (looped)\r\n    await queueAudio('./music/game-theme.mp3', this.musicChannel, { \r\n      loop: true, \r\n      volume: 0.4 \r\n    });\r\n    \r\n    // Immediate sound effects\r\n    await queueAudio('./sfx/sword-swing.wav', this.sfxChannel);\r\n    await queueAudio('./sfx/hit-impact.wav', this.sfxChannel);\r\n    \r\n    // Character dialog (interrupts other voice)\r\n    await queueAudioPriority('./voice/victory-shout.mp3', this.voiceChannel);\r\n  }\r\n  \r\n  async handleEmergency(): Promise<void> {\r\n    // Stop everything and play alert\r\n    stopCurrentAudioInChannel(this.musicChannel);\r\n    stopCurrentAudioInChannel(this.sfxChannel);\r\n    await queueAudioPriority('./alerts/game-over.mp3', this.voiceChannel);\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h3,{id:"podcast-queue-management",children:"Podcast Queue Management"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-typescript",children:"class PodcastQueueManager {\r\n  private contentChannel: number = 0;\r\n  private currentSegment: number = 0;\r\n  private segments: string[] = [];\r\n  \r\n  loadEpisode(segments: string[]): void {\r\n    this.segments = segments;\r\n    this.currentSegment = 0;\r\n  }\r\n  \r\n  async startEpisode(): Promise<void> {\r\n    if (this.segments.length === 0) return;\r\n    \r\n    // Queue all segments\r\n    for (const segment of this.segments) {\r\n      await queueAudio(segment, this.contentChannel);\r\n    }\r\n    \r\n    this.setupSegmentTracking();\r\n  }\r\n  \r\n  private setupSegmentTracking(): void {\r\n    onAudioComplete(this.contentChannel, (info) => {\r\n      this.currentSegment++;\r\n      console.log(`Completed segment ${this.currentSegment}: ${info.fileName}`);\r\n      \r\n      if (this.currentSegment >= this.segments.length) {\r\n        console.log('Episode completed!');\r\n      }\r\n    });\r\n  }\r\n  \r\n  async insertAdBreak(adUrls: string[]): Promise<void> {\r\n    // Pause main content\r\n    pauseChannel(this.contentChannel);\r\n    \r\n    // Queue ads\r\n    for (const ad of adUrls) {\r\n      await queueAudio(ad, 1); // Ad channel\r\n    }\r\n    \r\n    // Resume after all ads\r\n    onQueueChange(1, (snapshot) => {\r\n      if (snapshot.totalItems === 0 && !snapshot.isChannelActive) {\r\n        resumeChannel(this.contentChannel);\r\n      }\r\n    });\r\n  }\r\n}\n"})}),"\n",(0,a.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsx)(n.p,{children:"Now that you understand the queue system, explore:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/audio-queue-docs/core-concepts/event-system",children:"Event System"})})," - React to queue and playback events"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/audio-queue-docs/core-concepts/audio-lifecycle",children:"Audio Lifecycle"})})," - Complete audio playback flow"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/audio-queue-docs/core-concepts/performance-memory",children:"Performance & Memory"})})," - Optimization strategies"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:(0,a.jsx)(n.a,{href:"/audio-queue-docs/api-reference/queue-management",children:"API Reference"})})," - Detailed function documentation"]}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>u});var t=r(6540);const a={},i=t.createContext(a);function s(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function u(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);