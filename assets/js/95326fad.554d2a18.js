"use strict";(self.webpackChunkaudio_queue_docs=self.webpackChunkaudio_queue_docs||[]).push([[589],{8453:(n,e,r)=>{r.d(e,{R:()=>i,x:()=>s});var t=r(6540);const o={},a=t.createContext(o);function i(n){const e=t.useContext(a);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:i(n.components),t.createElement(a.Provider,{value:e},n.children)}},9049:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>i,metadata:()=>t,toc:()=>u});const t=JSON.parse('{"id":"core-concepts/event-system","title":"Event System","description":"Understanding the comprehensive event system that powers real-time audio monitoring and reactive programming patterns.","source":"@site/docs/core-concepts/event-system.md","sourceDirName":"core-concepts","slug":"/core-concepts/event-system","permalink":"/audio-queue-docs/core-concepts/event-system","draft":false,"unlisted":false,"editUrl":"https://github.com/tonycarpenter21/audio-queue-docs/tree/main/docs/core-concepts/event-system.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Queue System","permalink":"/audio-queue-docs/core-concepts/queue-system"},"next":{"title":"Audio Lifecycle","permalink":"/audio-queue-docs/core-concepts/audio-lifecycle"}}');var o=r(4848),a=r(8453);const i={},s="Event System",l={},u=[{value:"What is the Event System?",id:"what-is-the-event-system",level:2},{value:"Core Event Types",id:"core-event-types",level:2},{value:"Audio Start Events",id:"audio-start-events",level:3},{value:"Audio Complete Events",id:"audio-complete-events",level:3},{value:"Audio Progress Events",id:"audio-progress-events",level:3},{value:"Queue Change Events",id:"queue-change-events",level:3},{value:"Event Management Patterns",id:"event-management-patterns",level:2},{value:"Event Handler Classes",id:"event-handler-classes",level:3},{value:"Cross-Channel Event Coordination",id:"cross-channel-event-coordination",level:3},{value:"State Machine with Events",id:"state-machine-with-events",level:3},{value:"Advanced Event Patterns",id:"advanced-event-patterns",level:2},{value:"Event Aggregation",id:"event-aggregation",level:3},{value:"Event-Driven Analytics",id:"event-driven-analytics",level:3},{value:"Event Cleanup and Management",id:"event-cleanup-and-management",level:2},{value:"Event Handler Cleanup",id:"event-handler-cleanup",level:3},{value:"Performance-Aware Event Handling",id:"performance-aware-event-handling",level:3},{value:"Next Steps",id:"next-steps",level:2},{value:"Real-time Queue Monitoring",id:"real-time-queue-monitoring",level:3},{value:"Playlist Management",id:"playlist-management",level:3},{value:"Dynamic Content Insertion",id:"dynamic-content-insertion",level:3},{value:"Cross-Channel Synchronization",id:"cross-channel-synchronization",level:3},{value:"Efficient Queue Operations",id:"efficient-queue-operations",level:3}];function c(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"event-system",children:"Event System"})}),"\n",(0,o.jsx)(e.p,{children:"Understanding the comprehensive event system that powers real-time audio monitoring and reactive programming patterns."}),"\n",(0,o.jsx)(e.h2,{id:"what-is-the-event-system",children:"What is the Event System?"}),"\n",(0,o.jsx)(e.p,{children:"The audio-channel-queue package provides a rich event system that allows you to react to audio playback changes, queue modifications, and progress updates in real-time. Events are channel-specific and fire automatically during audio operations."}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"import { \r\n  onAudioStart, \r\n  onAudioComplete, \r\n  onAudioProgress, \r\n  onQueueChange \r\n} from 'audio-channel-queue';\r\n\r\n// React to audio starting\r\nonAudioStart(0, (info) => {\r\n  console.log(`Started playing: ${info.fileName}`);\r\n});\r\n\r\n// React to audio completing\r\nonAudioComplete(0, (info) => {\r\n  console.log(`Finished: ${info.fileName}`);\r\n  console.log(`Remaining in queue: ${info.remainingInQueue}`);\r\n});\r\n\r\n// Track playback progress\r\nonAudioProgress(0, (info) => {\r\n  console.log(`Progress: ${Math.round(info.progress * 100)}%`);\r\n});\r\n\r\n// Monitor queue changes\r\nonQueueChange(0, (snapshot) => {\r\n  console.log(`Queue now has ${snapshot.totalItems} items`);\r\n});\n"})}),"\n",(0,o.jsx)(e.h2,{id:"core-event-types",children:"Core Event Types"}),"\n",(0,o.jsx)(e.h3,{id:"audio-start-events",children:"Audio Start Events"}),"\n",(0,o.jsx)(e.p,{children:"Fired when audio begins playing on a channel:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"import { onAudioStart, AudioStartInfo } from 'audio-channel-queue';\r\n\r\nonAudioStart(0, (info: AudioStartInfo) => {\r\n  console.log('Audio started:', {\r\n    fileName: info.fileName,\r\n    duration: `${Math.round(info.duration / 1000)} seconds`,\r\n    volume: `${Math.round(info.volume * 100)}%`,\r\n    currentTime: info.currentTime\r\n  });\r\n  \r\n  // Example: Update UI\r\n  updateNowPlaying(info.fileName);\r\n  setProgressBarMax(info.duration);\r\n});\r\n\r\nfunction updateNowPlaying(fileName: string): void {\r\n  const element = document.getElementById('now-playing');\r\n  if (element) {\r\n    element.textContent = `Now Playing: ${fileName}`;\r\n  }\r\n}\r\n\r\nfunction setProgressBarMax(duration: number): void {\r\n  const progressBar = document.getElementById('progress') as HTMLProgressElement;\r\n  if (progressBar) {\r\n    progressBar.max = duration;\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"audio-complete-events",children:"Audio Complete Events"}),"\n",(0,o.jsx)(e.p,{children:"Fired when audio finishes playing (naturally or interrupted):"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"import { onAudioComplete, AudioCompleteInfo } from 'audio-channel-queue';\r\n\r\nonAudioComplete(0, (info: AudioCompleteInfo) => {\r\n  console.log('Audio completed:', {\r\n    fileName: info.fileName,\r\n    playbackDuration: `${Math.round(info.playbackDuration / 1000)} seconds`,\r\n    remainingInQueue: info.remainingInQueue,\r\n    wasInterrupted: info.wasInterrupted\r\n  });\r\n  \r\n  // Handle different completion scenarios\r\n  if (info.wasInterrupted) {\r\n    console.log('Playback was stopped early');\r\n    logInterruption(info.fileName, info.playbackDuration);\r\n  } else {\r\n    console.log('Playback completed naturally');\r\n    logSuccessfulPlayback(info.fileName);\r\n  }\r\n  \r\n  // Auto-play next or handle end of queue\r\n  if (info.remainingInQueue === 0) {\r\n    onQueueFinished();\r\n  }\r\n});\r\n\r\nfunction logInterruption(fileName: string, duration: number): void {\r\n  console.log(`${fileName} was interrupted after ${duration}ms`);\r\n}\r\n\r\nfunction logSuccessfulPlayback(fileName: string): void {\r\n  console.log(`${fileName} played to completion`);\r\n}\r\n\r\nfunction onQueueFinished(): void {\r\n  console.log('Queue is empty - playback session ended');\r\n  // Maybe start background music or show completion UI\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"audio-progress-events",children:"Audio Progress Events"}),"\n",(0,o.jsx)(e.p,{children:"Fired continuously during audio playback for real-time progress tracking:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"import { onAudioProgress, AudioProgressInfo } from 'audio-channel-queue';\r\n\r\nonAudioProgress(0, (info: AudioProgressInfo) => {\r\n  const percentage = Math.round(info.progress * 100);\r\n  const currentSeconds = Math.floor(info.currentTime / 1000);\r\n  const totalSeconds = Math.floor(info.duration / 1000);\r\n  \r\n  // Update progress display\r\n  updateProgressDisplay(percentage, currentSeconds, totalSeconds);\r\n  \r\n  // Trigger events at specific progress points\r\n  if (info.progress >= 0.25 && info.progress < 0.26) {\r\n    console.log('25% complete');\r\n    onQuarterProgress(info.fileName);\r\n  }\r\n  \r\n  if (info.progress >= 0.5 && info.progress < 0.51) {\r\n    console.log('50% complete');\r\n    onHalfwayProgress(info.fileName);\r\n  }\r\n  \r\n  if (info.progress >= 0.75 && info.progress < 0.76) {\r\n    console.log('75% complete');\r\n    onThreeQuarterProgress(info.fileName);\r\n  }\r\n});\r\n\r\nfunction updateProgressDisplay(percentage: number, current: number, total: number): void {\r\n  // Update progress bar\r\n  const progressBar = document.getElementById('progress') as HTMLProgressElement;\r\n  if (progressBar) {\r\n    progressBar.value = percentage;\r\n  }\r\n  \r\n  // Update time display\r\n  const timeDisplay = document.getElementById('time-display');\r\n  if (timeDisplay) {\r\n    timeDisplay.textContent = `${current}s / ${total}s (${percentage}%)`;\r\n  }\r\n}\r\n\r\nfunction onQuarterProgress(fileName: string): void {\r\n  console.log(`${fileName} is 25% complete`);\r\n}\r\n\r\nfunction onHalfwayProgress(fileName: string): void {\r\n  console.log(`${fileName} is 50% complete - halfway point reached`);\r\n}\r\n\r\nfunction onThreeQuarterProgress(fileName: string): void {\r\n  console.log(`${fileName} is 75% complete - almost finished`);\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"queue-change-events",children:"Queue Change Events"}),"\n",(0,o.jsx)(e.p,{children:"Fired when the queue is modified (items added, removed, or reordered):"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"import { onQueueChange, QueueSnapshot } from 'audio-channel-queue';\r\n\r\nonQueueChange(0, (snapshot: QueueSnapshot) => {\r\n  console.log('Queue changed:', {\r\n    totalItems: snapshot.totalItems,\r\n    currentlyPlaying: snapshot.currentlyPlaying,\r\n    isChannelActive: snapshot.isChannelActive\r\n  });\r\n  \r\n  // Update queue display\r\n  updateQueueDisplay(snapshot);\r\n  \r\n  // Handle queue state changes\r\n  if (snapshot.totalItems === 0) {\r\n    onQueueEmpty();\r\n  } else if (snapshot.totalItems === 1) {\r\n    onLastItem(snapshot.currentlyPlaying);\r\n  } else if (snapshot.totalItems > 10) {\r\n    onQueueOverloaded(snapshot.totalItems);\r\n  }\r\n});\r\n\r\nfunction updateQueueDisplay(snapshot: QueueSnapshot): void {\r\n  const queueList = document.getElementById('queue-list');\r\n  if (!queueList) return;\r\n  \r\n  queueList.innerHTML = '';\r\n  snapshot.items.forEach((item, index) => {\r\n    const listItem = document.createElement('li');\r\n    listItem.className = item.isCurrentlyPlaying ? 'playing' : 'queued';\r\n    listItem.textContent = `${item.position}. ${item.fileName}`;\r\n    queueList.appendChild(listItem);\r\n  });\r\n}\r\n\r\nfunction onQueueEmpty(): void {\r\n  console.log('Queue is now empty');\r\n  // Maybe show \"Add music\" prompt\r\n}\r\n\r\nfunction onLastItem(fileName: string | null): void {\r\n  console.log(`Last item in queue: ${fileName}`);\r\n  // Maybe start preloading next playlist\r\n}\r\n\r\nfunction onQueueOverloaded(count: number): void {\r\n  console.warn(`Queue has ${count} items - may impact performance`);\r\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"event-management-patterns",children:"Event Management Patterns"}),"\n",(0,o.jsx)(e.h3,{id:"event-handler-classes",children:"Event Handler Classes"}),"\n",(0,o.jsx)(e.p,{children:"Organize event handling with dedicated classes:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class AudioEventManager {\r\n  private channel: number;\r\n  private isSetup: boolean = false;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.channel = channel;\r\n  }\r\n  \r\n  setupAllEventHandlers(): void {\r\n    if (this.isSetup) return;\r\n    \r\n    this.setupStartHandler();\r\n    this.setupCompleteHandler();\r\n    this.setupProgressHandler();\r\n    this.setupQueueHandler();\r\n    \r\n    this.isSetup = true;\r\n    console.log(`Event handlers setup for channel ${this.channel}`);\r\n  }\r\n  \r\n  private setupStartHandler(): void {\r\n    onAudioStart(this.channel, (info) => {\r\n      console.log(`[${this.channel}] Started: ${info.fileName}`);\r\n      this.onAudioStarted(info);\r\n    });\r\n  }\r\n  \r\n  private setupCompleteHandler(): void {\r\n    onAudioComplete(this.channel, (info) => {\r\n      console.log(`[${this.channel}] Completed: ${info.fileName}`);\r\n      this.onAudioCompleted(info);\r\n    });\r\n  }\r\n  \r\n  private setupProgressHandler(): void {\r\n    onAudioProgress(this.channel, (info) => {\r\n      this.onAudioProgress(info);\r\n    });\r\n  }\r\n  \r\n  private setupQueueHandler(): void {\r\n    onQueueChange(this.channel, (snapshot) => {\r\n      console.log(`[${this.channel}] Queue changed: ${snapshot.totalItems} items`);\r\n      this.onQueueChanged(snapshot);\r\n    });\r\n  }\r\n  \r\n  // Override these methods in subclasses\r\n  protected onAudioStarted(info: AudioStartInfo): void {\r\n    // Default implementation\r\n  }\r\n  \r\n  protected onAudioCompleted(info: AudioCompleteInfo): void {\r\n    // Default implementation\r\n  }\r\n  \r\n  protected onAudioProgress(info: AudioProgressInfo): void {\r\n    // Default implementation - called frequently\r\n  }\r\n  \r\n  protected onQueueChanged(snapshot: QueueSnapshot): void {\r\n    // Default implementation\r\n  }\r\n}\r\n\r\n// Gaming-specific event handler\r\nclass GameAudioEventManager extends AudioEventManager {\r\n  protected onAudioStarted(info: AudioStartInfo): void {\r\n    // Update game UI\r\n    this.updateGameUI(`Playing: ${info.fileName}`);\r\n    \r\n    // Log for analytics\r\n    this.logGameAudioEvent('start', info.fileName);\r\n  }\r\n  \r\n  protected onAudioCompleted(info: AudioCompleteInfo): void {\r\n    if (info.wasInterrupted) {\r\n      console.log('Game audio was interrupted - might be important dialog');\r\n    }\r\n    \r\n    this.logGameAudioEvent('complete', info.fileName);\r\n  }\r\n  \r\n  private updateGameUI(message: string): void {\r\n    // Update game interface\r\n    console.log(`Game UI: ${message}`);\r\n  }\r\n  \r\n  private logGameAudioEvent(type: string, fileName: string): void {\r\n    // Send to analytics\r\n    console.log(`Analytics: ${type} - ${fileName}`);\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"cross-channel-event-coordination",children:"Cross-Channel Event Coordination"}),"\n",(0,o.jsx)(e.p,{children:"Coordinate events across multiple channels:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class MultiChannelEventCoordinator {\r\n  private musicChannel: number = 0;\r\n  private sfxChannel: number = 1;\r\n  private voiceChannel: number = 2;\r\n  \r\n  setupCrossChannelCoordination(): void {\r\n    this.setupVoiceDucking();\r\n    this.setupMusicTransitions();\r\n    this.setupSfxLimiting();\r\n  }\r\n  \r\n  private setupVoiceDucking(): void {\r\n    // Duck music and SFX when voice starts\r\n    onAudioStart(this.voiceChannel, () => {\r\n      console.log('Voice started - ducking other channels');\r\n      duckChannelVolume(this.musicChannel, 0.2);\r\n      duckChannelVolume(this.sfxChannel, 0.3);\r\n    });\r\n    \r\n    // Restore volume when voice ends\r\n    onAudioComplete(this.voiceChannel, () => {\r\n      console.log('Voice ended - restoring channel volumes');\r\n      restoreChannelVolume(this.musicChannel);\r\n      restoreChannelVolume(this.sfxChannel);\r\n    });\r\n  }\r\n  \r\n  private setupMusicTransitions(): void {\r\n    onAudioComplete(this.musicChannel, (info) => {\r\n      if (!info.wasInterrupted) {\r\n        console.log('Music track completed naturally');\r\n        this.considerNextTrack();\r\n      }\r\n    });\r\n  }\r\n  \r\n  private setupSfxLimiting(): void {\r\n    onQueueChange(this.sfxChannel, (snapshot) => {\r\n      if (snapshot.totalItems > 5) {\r\n        console.warn('Too many SFX queued - consider throttling');\r\n        this.throttleSfx();\r\n      }\r\n    });\r\n  }\r\n  \r\n  private considerNextTrack(): void {\r\n    // Logic to decide next music track\r\n    console.log('Considering next music track...');\r\n  }\r\n  \r\n  private throttleSfx(): void {\r\n    // Logic to limit SFX queue\r\n    console.log('Throttling SFX to prevent overload');\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"state-machine-with-events",children:"State Machine with Events"}),"\n",(0,o.jsx)(e.p,{children:"Use events to drive complex state machines:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"enum AudioState {\r\n  IDLE = 'idle',\r\n  LOADING = 'loading',\r\n  PLAYING = 'playing',\r\n  PAUSED = 'paused',\r\n  COMPLETING = 'completing'\r\n}\r\n\r\nclass AudioStateMachine {\r\n  private state: AudioState = AudioState.IDLE;\r\n  private channel: number;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.channel = channel;\r\n    this.setupStateMachine();\r\n  }\r\n  \r\n  private setupStateMachine(): void {\r\n    onAudioStart(this.channel, () => {\r\n      this.transitionTo(AudioState.PLAYING);\r\n    });\r\n    \r\n    onAudioComplete(this.channel, (info) => {\r\n      if (info.remainingInQueue > 0) {\r\n        this.transitionTo(AudioState.LOADING);\r\n      } else {\r\n        this.transitionTo(AudioState.IDLE);\r\n      }\r\n    });\r\n    \r\n    onAudioProgress(this.channel, (info) => {\r\n      if (this.state === AudioState.PLAYING) {\r\n        if (info.progress > 0.9) {\r\n          this.transitionTo(AudioState.COMPLETING);\r\n        }\r\n      }\r\n    });\r\n  }\r\n  \r\n  private transitionTo(newState: AudioState): void {\r\n    const oldState = this.state;\r\n    this.state = newState;\r\n    \r\n    console.log(`State transition: ${oldState} \u2192 ${newState}`);\r\n    \r\n    // Handle state-specific logic\r\n    switch (newState) {\r\n      case AudioState.IDLE:\r\n        this.onIdle();\r\n        break;\r\n      case AudioState.PLAYING:\r\n        this.onPlaying();\r\n        break;\r\n      case AudioState.COMPLETING:\r\n        this.onCompleting();\r\n        break;\r\n    }\r\n  }\r\n  \r\n  private onIdle(): void {\r\n    console.log('Audio system is idle');\r\n    // Maybe start background music\r\n  }\r\n  \r\n  private onPlaying(): void {\r\n    console.log('Audio is playing');\r\n    // Update UI to show play state\r\n  }\r\n  \r\n  private onCompleting(): void {\r\n    console.log('Audio is near completion');\r\n    // Maybe preload next track or show completion animation\r\n  }\r\n  \r\n  getCurrentState(): AudioState {\r\n    return this.state;\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"advanced-event-patterns",children:"Advanced Event Patterns"}),"\n",(0,o.jsx)(e.h3,{id:"event-aggregation",children:"Event Aggregation"}),"\n",(0,o.jsx)(e.p,{children:"Collect and analyze events across time periods:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class AudioEventAggregator {\r\n  private events: { type: string; timestamp: number; data: any }[] = [];\r\n  private maxEvents: number = 1000;\r\n  \r\n  constructor() {\r\n    this.setupEventCollection();\r\n  }\r\n  \r\n  private setupEventCollection(): void {\r\n    // Collect all events from channel 0\r\n    onAudioStart(0, (info) => {\r\n      this.recordEvent('audioStart', info);\r\n    });\r\n    \r\n    onAudioComplete(0, (info) => {\r\n      this.recordEvent('audioComplete', info);\r\n    });\r\n    \r\n    onQueueChange(0, (snapshot) => {\r\n      this.recordEvent('queueChange', { totalItems: snapshot.totalItems });\r\n    });\r\n  }\r\n  \r\n  private recordEvent(type: string, data: any): void {\r\n    this.events.push({\r\n      type,\r\n      timestamp: Date.now(),\r\n      data\r\n    });\r\n    \r\n    // Keep only recent events\r\n    if (this.events.length > this.maxEvents) {\r\n      this.events = this.events.slice(-this.maxEvents);\r\n    }\r\n  }\r\n  \r\n  getEventsSince(timestampMs: number): any[] {\r\n    return this.events.filter(event => event.timestamp >= timestampMs);\r\n  }\r\n  \r\n  getEventStats(periodMs: number = 60000): {\r\n    starts: number;\r\n    completions: number;\r\n    queueChanges: number;\r\n    avgPlaybackDuration: number;\r\n  } {\r\n    const since = Date.now() - periodMs;\r\n    const recentEvents = this.getEventsSince(since);\r\n    \r\n    const starts = recentEvents.filter(e => e.type === 'audioStart').length;\r\n    const completions = recentEvents.filter(e => e.type === 'audioComplete').length;\r\n    const queueChanges = recentEvents.filter(e => e.type === 'queueChange').length;\r\n    \r\n    // Calculate average playback duration\r\n    const durations = recentEvents\r\n      .filter(e => e.type === 'audioComplete')\r\n      .map(e => e.data.playbackDuration);\r\n    \r\n    const avgPlaybackDuration = durations.length > 0 \r\n      ? durations.reduce((a, b) => a + b, 0) / durations.length \r\n      : 0;\r\n    \r\n    return { starts, completions, queueChanges, avgPlaybackDuration };\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"event-driven-analytics",children:"Event-Driven Analytics"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class AudioAnalytics {\r\n  private sessionStart: number = Date.now();\r\n  private playbackStats: Map<string, { count: number; totalDuration: number }> = new Map();\r\n  \r\n  constructor() {\r\n    this.setupAnalytics();\r\n  }\r\n  \r\n  private setupAnalytics(): void {\r\n    onAudioStart(0, (info) => {\r\n      this.trackAudioStart(info);\r\n    });\r\n    \r\n    onAudioComplete(0, (info) => {\r\n      this.trackAudioComplete(info);\r\n    });\r\n    \r\n    onAudioProgress(0, (info) => {\r\n      this.trackProgress(info);\r\n    });\r\n  }\r\n  \r\n  private trackAudioStart(info: AudioStartInfo): void {\r\n    console.log(`\ud83d\udcca Analytics: Started ${info.fileName}`);\r\n    \r\n    // Initialize or increment play count\r\n    const stats = this.playbackStats.get(info.fileName) || { count: 0, totalDuration: 0 };\r\n    stats.count++;\r\n    this.playbackStats.set(info.fileName, stats);\r\n  }\r\n  \r\n  private trackAudioComplete(info: AudioCompleteInfo): void {\r\n    console.log(`\ud83d\udcca Analytics: Completed ${info.fileName} (${info.playbackDuration}ms)`);\r\n    \r\n    // Update duration stats\r\n    const stats = this.playbackStats.get(info.fileName);\r\n    if (stats) {\r\n      stats.totalDuration += info.playbackDuration;\r\n      this.playbackStats.set(info.fileName, stats);\r\n    }\r\n    \r\n    // Track completion rate\r\n    if (!info.wasInterrupted) {\r\n      console.log(`\u2705 ${info.fileName} played to completion`);\r\n    } else {\r\n      console.log(`\u23f9\ufe0f ${info.fileName} was interrupted`);\r\n    }\r\n  }\r\n  \r\n  private trackProgress(info: AudioProgressInfo): void {\r\n    // Track milestone progress (only log once per milestone)\r\n    const milestones = [0.25, 0.5, 0.75];\r\n    for (const milestone of milestones) {\r\n      if (info.progress >= milestone && info.progress < milestone + 0.01) {\r\n        console.log(`\ud83d\udcca Analytics: ${info.fileName} reached ${milestone * 100}%`);\r\n      }\r\n    }\r\n  }\r\n  \r\n  getSessionReport(): {\r\n    sessionDuration: number;\r\n    filesPlayed: string[];\r\n    mostPlayedFile: string | null;\r\n    totalPlaybackTime: number;\r\n  } {\r\n    const sessionDuration = Date.now() - this.sessionStart;\r\n    const filesPlayed = Array.from(this.playbackStats.keys());\r\n    \r\n    let mostPlayedFile: string | null = null;\r\n    let maxCount = 0;\r\n    let totalPlaybackTime = 0;\r\n    \r\n    for (const [fileName, stats] of this.playbackStats) {\r\n      if (stats.count > maxCount) {\r\n        maxCount = stats.count;\r\n        mostPlayedFile = fileName;\r\n      }\r\n      totalPlaybackTime += stats.totalDuration;\r\n    }\r\n    \r\n    return {\r\n      sessionDuration,\r\n      filesPlayed,\r\n      mostPlayedFile,\r\n      totalPlaybackTime\r\n    };\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"event-cleanup-and-management",children:"Event Cleanup and Management"}),"\n",(0,o.jsx)(e.h3,{id:"event-handler-cleanup",children:"Event Handler Cleanup"}),"\n",(0,o.jsx)(e.p,{children:"Properly manage event handler lifecycle:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class EventHandlerManager {\r\n  private cleanupFunctions: Array<() => void> = [];\r\n  \r\n  addEventHandler(\r\n    channel: number, \r\n    eventType: 'start' | 'complete' | 'progress' | 'queueChange',\r\n    handler: any\r\n  ): void {\r\n    let cleanup: () => void;\r\n    \r\n    switch (eventType) {\r\n      case 'start':\r\n        cleanup = onAudioStart(channel, handler);\r\n        break;\r\n      case 'complete':\r\n        cleanup = onAudioComplete(channel, handler);\r\n        break;\r\n      case 'progress':\r\n        cleanup = onAudioProgress(channel, handler);\r\n        break;\r\n      case 'queueChange':\r\n        cleanup = onQueueChange(channel, handler);\r\n        break;\r\n      default:\r\n        throw new Error(`Unknown event type: ${eventType}`);\r\n    }\r\n    \r\n    this.cleanupFunctions.push(cleanup);\r\n  }\r\n  \r\n  removeAllEventHandlers(): void {\r\n    console.log(`Cleaning up ${this.cleanupFunctions.length} event handlers`);\r\n    \r\n    for (const cleanup of this.cleanupFunctions) {\r\n      cleanup();\r\n    }\r\n    \r\n    this.cleanupFunctions = [];\r\n  }\r\n  \r\n  getHandlerCount(): number {\r\n    return this.cleanupFunctions.length;\r\n  }\r\n}\r\n\r\n// Usage\r\nconst eventManager = new EventHandlerManager();\r\n\r\n// Add handlers\r\neventManager.addEventHandler(0, 'start', (info) => {\r\n  console.log(`Started: ${info.fileName}`);\r\n});\r\n\r\neventManager.addEventHandler(0, 'complete', (info) => {\r\n  console.log(`Completed: ${info.fileName}`);\r\n});\r\n\r\n// Later, clean up when component unmounts or page unloads\r\nwindow.addEventListener('beforeunload', () => {\r\n  eventManager.removeAllEventHandlers();\r\n});\n"})}),"\n",(0,o.jsx)(e.h3,{id:"performance-aware-event-handling",children:"Performance-Aware Event Handling"}),"\n",(0,o.jsx)(e.p,{children:"Handle high-frequency events efficiently:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class PerformantEventHandler {\r\n  private lastProgressUpdate: number = 0;\r\n  private progressThrottle: number = 100; // Update every 100ms max\r\n  \r\n  setupOptimizedEventHandlers(channel: number): void {\r\n    // Standard frequency events\r\n    onAudioStart(channel, (info) => {\r\n      this.handleAudioStart(info);\r\n    });\r\n    \r\n    onAudioComplete(channel, (info) => {\r\n      this.handleAudioComplete(info);\r\n    });\r\n    \r\n    // Throttled high-frequency events\r\n    onAudioProgress(channel, (info) => {\r\n      this.handleThrottledProgress(info);\r\n    });\r\n    \r\n    onQueueChange(channel, (snapshot) => {\r\n      this.handleQueueChange(snapshot);\r\n    });\r\n  }\r\n  \r\n  private handleAudioStart(info: AudioStartInfo): void {\r\n    // Immediate response for start events\r\n    console.log(`Quick start: ${info.fileName}`);\r\n  }\r\n  \r\n  private handleAudioComplete(info: AudioCompleteInfo): void {\r\n    // Immediate response for completion events\r\n    console.log(`Quick complete: ${info.fileName}`);\r\n  }\r\n  \r\n  private handleThrottledProgress(info: AudioProgressInfo): void {\r\n    const now = Date.now();\r\n    \r\n    if (now - this.lastProgressUpdate >= this.progressThrottle) {\r\n      this.lastProgressUpdate = now;\r\n      \r\n      // Only update UI at reasonable intervals\r\n      this.updateProgressUI(info);\r\n    }\r\n  }\r\n  \r\n  private updateProgressUI(info: AudioProgressInfo): void {\r\n    // Expensive UI updates only when throttled\r\n    const percentage = Math.round(info.progress * 100);\r\n    console.log(`Progress: ${percentage}%`);\r\n  }\r\n  \r\n  private handleQueueChange(snapshot: QueueSnapshot): void {\r\n    // Queue changes are less frequent but important\r\n    console.log(`Queue: ${snapshot.totalItems} items`);\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(e.p,{children:"Now that you understand the event system, explore:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"/audio-queue-docs/core-concepts/audio-lifecycle",children:"Audio Lifecycle"})})," - Complete audio playback flow with events"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"/audio-queue-docs/core-concepts/performance-memory",children:"Performance & Memory"})})," - Optimization strategies for events"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"/audio-queue-docs/api-reference/event-listeners",children:"API Reference"})})," - Detailed event documentation"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:(0,o.jsx)(e.a,{href:"../getting-started/basic-usage",children:"Examples"})})," - Real-world event handling patterns"]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"real-time-queue-monitoring",children:"Real-time Queue Monitoring"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"import { onQueueChange } from 'audio-channel-queue';\r\n\r\nclass QueueMonitor {\r\n  setupQueueTracking(channel: number): void {\r\n    onQueueChange(channel, (snapshot) => {\r\n      console.log(`Queue changed on channel ${channel}:`);\r\n      console.log(`- Items: ${snapshot.totalItems}`);\r\n      console.log(`- Playing: ${snapshot.currentlyPlaying}`);\r\n      \r\n      // React to queue events\r\n      if (snapshot.totalItems === 0) {\r\n        this.onQueueEmpty(channel);\r\n      } else if (snapshot.totalItems > 10) {\r\n        this.onQueueOverloaded(channel);\r\n      }\r\n    });\r\n  }\r\n  \r\n  onQueueEmpty(channel: number): void {\r\n    console.log(`Channel ${channel} queue is empty - maybe start background music?`);\r\n  }\r\n  \r\n  onQueueOverloaded(channel: number): void {\r\n    console.log(`Channel ${channel} queue is getting long - consider optimization`);\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"playlist-management",children:"Playlist Management"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class PlaylistManager {\r\n  private playlist: string[] = [];\r\n  private currentIndex: number = 0;\r\n  private channel: number = 0;\r\n  \r\n  constructor(channel: number = 0) {\r\n    this.channel = channel;\r\n    this.setupEventHandlers();\r\n  }\r\n  \r\n  loadPlaylist(audioFiles: string[]): void {\r\n    this.playlist = [...audioFiles];\r\n    this.currentIndex = 0;\r\n  }\r\n  \r\n  async startPlaylist(): Promise<void> {\r\n    if (this.playlist.length === 0) return;\r\n    \r\n    // Queue all tracks\r\n    for (const track of this.playlist) {\r\n      if (this.channel === 0) {\r\n        await queueAudio(track);\r\n      } else {\r\n        await queueAudio(track, this.channel);\r\n      }\r\n    }\r\n  }\r\n  \r\n  async skipToNext(): Promise<void> {\r\n    // Stop current and play next\r\n    if (this.channel === 0) {\r\n      stopCurrentAudioInChannel();\r\n    } else {\r\n      stopCurrentAudioInChannel(this.channel);\r\n    }\r\n    \r\n    this.currentIndex++;\r\n    if (this.currentIndex < this.playlist.length) {\r\n      if (this.channel === 0) {\r\n        await queueAudioPriority(this.playlist[this.currentIndex]);\r\n      } else {\r\n        await queueAudioPriority(this.playlist[this.currentIndex], this.channel);\r\n      }\r\n    }\r\n  }\r\n  \r\n  async skipToPrevious(): Promise<void> {\r\n    this.currentIndex = Math.max(0, this.currentIndex - 1);\r\n    if (this.channel === 0) {\r\n      stopCurrentAudioInChannel();\r\n      await queueAudioPriority(this.playlist[this.currentIndex]);\r\n    } else {\r\n      stopCurrentAudioInChannel(this.channel);\r\n      await queueAudioPriority(this.playlist[this.currentIndex], this.channel);\r\n    }\r\n  }\r\n  \r\n  private setupEventHandlers(): void {\r\n    onAudioComplete(this.channel, (info) => {\r\n      console.log(`Completed: ${info.fileName}`);\r\n      \r\n      // Auto-advance playlist\r\n      if (info.remainingInQueue === 0 && this.currentIndex < this.playlist.length - 1) {\r\n        this.skipToNext();\r\n      }\r\n    });\r\n  }\r\n}\r\n\r\n// Usage\r\nconst musicPlayer = new PlaylistManager(0);\r\nmusicPlayer.loadPlaylist([\r\n  './music/track1.mp3',\r\n  './music/track2.mp3', \r\n  './music/track3.mp3'\r\n]);\r\nawait musicPlayer.startPlaylist();\n"})}),"\n",(0,o.jsx)(e.h3,{id:"dynamic-content-insertion",children:"Dynamic Content Insertion"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class DynamicContentManager {\r\n  private baseChannel: number = 0;\r\n  private adChannel: number = 1;\r\n  \r\n  async startMainContent(contentUrl: string): Promise<void> {\r\n    await queueAudio(contentUrl); // Using default channel 0\r\n  }\r\n  \r\n  async insertAd(adUrl: string, returnToContent: boolean = true): Promise<void> {\r\n    // Pause main content\r\n    pauseChannel(this.baseChannel);\r\n    \r\n    // Play ad on separate channel\r\n    await queueAudioPriority(adUrl, this.adChannel);\r\n    \r\n    if (returnToContent) {\r\n      // Resume main content when ad finishes\r\n      onAudioComplete(this.adChannel, () => {\r\n        resumeChannel(this.baseChannel);\r\n      });\r\n    }\r\n  }\r\n  \r\n  async insertBreakingNews(newsUrl: string): Promise<void> {\r\n    // Interrupt everything with priority news\r\n    await queueAudioPriority(newsUrl); // Using default channel 0\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"cross-channel-synchronization",children:"Cross-Channel Synchronization"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class SynchronizedQueueManager {\r\n  async syncChannelPlayback(channel1: number, channel2: number): Promise<void> {\r\n    // Start audio on both channels simultaneously\r\n    const promises = [\r\n      channel1 === 0 ? queueAudio('./audio/left-channel.mp3') : queueAudio('./audio/left-channel.mp3', channel1),\r\n      channel2 === 0 ? queueAudio('./audio/right-channel.mp3') : queueAudio('./audio/right-channel.mp3', channel2)\r\n    ];\r\n    \r\n    await Promise.all(promises);\r\n    console.log('Synchronized playback started on both channels');\r\n  }\r\n  \r\n  async createCallAndResponse(callTrack: string, responseTrack: string): Promise<void> {\r\n    // Play call on channel 0\r\n    await queueAudio(callTrack); // Using default channel 0\r\n    \r\n    // When call finishes, play response on channel 1\r\n    onAudioComplete(0, async () => {\r\n      await queueAudio(responseTrack, 1);\r\n    });\r\n  }\r\n  \r\n  async orchestrateMultiChannelSequence(): Promise<void> {\r\n    // Complex multi-channel coordination\r\n    \r\n    // Start background music (using default channel 0)\r\n    await queueAudio('./music/background.mp3', 0, { loop: true, volume: 0.3 });\r\n    \r\n    // Layer in sound effects\r\n    setTimeout(() => queueAudio('./sfx/wind.mp3', 1), 2000);\r\n    setTimeout(() => queueAudio('./sfx/birds.mp3', 2), 4000);\r\n    \r\n    // Add narration that ducks other audio\r\n    setTimeout(async () => {\r\n      // Duck background channels\r\n      setChannelVolume(0, 0.1);\r\n      setChannelVolume(1, 0.2);\r\n      setChannelVolume(2, 0.2);\r\n      \r\n      // Play narration\r\n      await queueAudio('./voice/narration.mp3', 3);\r\n      \r\n      // Restore volumes when narration ends\r\n      onAudioComplete(3, () => {\r\n        setChannelVolume(0, 0.3);\r\n        setChannelVolume(1, 1.0);\r\n        setChannelVolume(2, 1.0);\r\n      });\r\n    }, 6000);\r\n  }\r\n}\n"})}),"\n",(0,o.jsx)(e.h3,{id:"efficient-queue-operations",children:"Efficient Queue Operations"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-typescript",children:"class EfficientQueueManager {\r\n  private queueCache: Map<number, QueueSnapshot> = new Map();\r\n  private cacheTimeout: number = 1000; // 1 second cache\r\n  \r\n  getCachedQueueSnapshot(channel: number): QueueSnapshot {\r\n    const cached = this.queueCache.get(channel);\r\n    if (cached) {\r\n      return cached;\r\n    }\r\n    \r\n    const snapshot = channel === 0 ? getQueueSnapshot() : getQueueSnapshot(channel);\r\n    this.queueCache.set(channel, snapshot);\r\n    \r\n    // Clear cache after timeout\r\n    setTimeout(() => {\r\n      this.queueCache.delete(channel);\r\n    }, this.cacheTimeout);\r\n    \r\n    return snapshot;\r\n  }\r\n  \r\n  async batchQueueAudio(audioFiles: string[], channel: number): Promise<void> {\r\n    // Queue multiple files efficiently\r\n    const promises = audioFiles.map(file => \r\n      channel === 0 ? queueAudio(file) : queueAudio(file, channel)\r\n    );\r\n    await Promise.all(promises);\r\n    console.log(`Batch queued ${audioFiles.length} files on channel ${channel}`);\r\n  }\r\n  \r\n  optimizeQueueSize(channel: number, maxItems: number = 5): void {\r\n    const snapshot = this.getCachedQueueSnapshot(channel);\r\n    \r\n    if (snapshot.totalItems > maxItems) {\r\n      console.warn(`Channel ${channel} queue has ${snapshot.totalItems} items, above optimal size of ${maxItems}`);\r\n      // Consider stopping current audio to clear queue\r\n    }\r\n  }\r\n}\n"})})]})}function d(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(c,{...n})}):c(n)}}}]);