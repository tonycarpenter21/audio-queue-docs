"use strict";(self.webpackChunkaudio_queue_docs=self.webpackChunkaudio_queue_docs||[]).push([[317],{7211:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"core-concepts/audio-channels","title":"Audio Channels","description":"Understanding the channel-based architecture that enables simultaneous audio playback and management.","source":"@site/docs/core-concepts/audio-channels.md","sourceDirName":"core-concepts","slug":"/core-concepts/audio-channels","permalink":"/audio-queue-docs/core-concepts/audio-channels","draft":false,"unlisted":false,"editUrl":"https://github.com/tonycarpenter21/audio-queue-docs/tree/main/docs/core-concepts/audio-channels.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Browser Compatibility","permalink":"/audio-queue-docs/getting-started/browser-compatibility"},"next":{"title":"Queue System","permalink":"/audio-queue-docs/core-concepts/queue-system"}}');var i=a(4848),o=a(8453);const t={},s="Audio Channels",l={},c=[{value:"What Are Audio Channels?",id:"what-are-audio-channels",level:2},{value:"Channel Architecture",id:"channel-architecture",level:2},{value:"Independent Operation",id:"independent-operation",level:3},{value:"Channel Numbering",id:"channel-numbering",level:3},{value:"Common Channel Patterns",id:"common-channel-patterns",level:2},{value:"Gaming Applications",id:"gaming-applications",level:3},{value:"Podcast/Media Applications",id:"podcastmedia-applications",level:3},{value:"Interactive Applications",id:"interactive-applications",level:3},{value:"Channel Management Best Practices",id:"channel-management-best-practices",level:2},{value:"Resource Management",id:"resource-management",level:3},{value:"Volume Balancing",id:"volume-balancing",level:3},{value:"Event Coordination",id:"event-coordination",level:3},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Optimal Channel Count",id:"optimal-channel-count",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Next Steps",id:"next-steps",level:2}];function u(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"audio-channels",children:"Audio Channels"})}),"\n",(0,i.jsx)(e.p,{children:"Understanding the channel-based architecture that enables simultaneous audio playback and management."}),"\n",(0,i.jsx)(e.h2,{id:"what-are-audio-channels",children:"What Are Audio Channels?"}),"\n",(0,i.jsx)(e.p,{children:'Audio channels are independent playback streams that allow you to organize and control different types of audio content separately. Think of channels as separate "audio tracks" that can play simultaneously without interfering with each other.'}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"import { queueAudio, setChannelVolume } from 'audio-channel-queue';\r\n\r\n// Channel 0: Background music (using default channel)\r\nawait queueAudio('./music/ambient.mp3');\r\nsetChannelVolume(0, 0.3);\r\n\r\n// Channel 1: Sound effects\r\nawait queueAudio('./sfx/explosion.wav', 1);\r\nsetChannelVolume(1, 0.8);\r\n\r\n// Channel 2: Voice/dialog\r\nawait queueAudio('./voice/character1.mp3', 2);\r\nsetChannelVolume(2, 1.0);\n"})}),"\n",(0,i.jsx)(e.h2,{id:"channel-architecture",children:"Channel Architecture"}),"\n",(0,i.jsx)(e.h3,{id:"independent-operation",children:"Independent Operation"}),"\n",(0,i.jsx)(e.p,{children:"Each channel operates completely independently:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Separate Queues"}),": Each channel maintains its own audio queue"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Independent Volume"}),": Volume controls affect only the specific channel"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Isolated Playback"}),": Pause/resume operations work per channel"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Event Isolation"}),": Events are fired per channel"]}),"\n"]}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"import { \r\n  getCurrentAudioInfo, \r\n  pauseChannel, \r\n  resumeChannel,\r\n  getQueueSnapshot \r\n} from 'audio-channel-queue';\r\n\r\n// Check what's playing on each channel\r\nconst musicInfo = getCurrentAudioInfo();    // Background music (default channel 0)\r\nconst sfxInfo = getCurrentAudioInfo(1);      // Sound effects\r\nconst voiceInfo = getCurrentAudioInfo(2);    // Dialog\r\n\r\n// Pause only the music channel\r\npauseChannel(0);\r\n\r\n// Voice and SFX continue playing normally\r\nconsole.log('Music paused, but voice and SFX still playing');\r\n\r\n// Each channel has its own queue\r\nconst musicQueue = getQueueSnapshot();   // Default channel 0\r\nconst sfxQueue = getQueueSnapshot(1);\r\nconst voiceQueue = getQueueSnapshot(2);\n"})}),"\n",(0,i.jsx)(e.h3,{id:"channel-numbering",children:"Channel Numbering"}),"\n",(0,i.jsx)(e.p,{children:"Channels are identified by zero-based integers:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"// Valid channel numbers\r\nconst channels = {\r\n  MUSIC: 0,\r\n  SFX: 1,\r\n  VOICE: 2,\r\n  AMBIENT: 3,\r\n  UI_SOUNDS: 4\r\n  // ... any number you need\r\n};\r\n\r\n// Use descriptive constants for better code organization\r\nawait queueAudio('./music/battle.mp3', channels.MUSIC);\r\nawait queueAudio('./voice/warning.mp3', channels.VOICE);\n"})}),"\n",(0,i.jsx)(e.h2,{id:"common-channel-patterns",children:"Common Channel Patterns"}),"\n",(0,i.jsx)(e.h3,{id:"gaming-applications",children:"Gaming Applications"}),"\n",(0,i.jsx)(e.p,{children:"Typical channel organization for games:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"const GameChannels = {\r\n  MUSIC: 0,           // Background music\r\n  SFX: 1,             // Sound effects\r\n  VOICE: 2,           // Character dialog\r\n  AMBIENT: 3,         // Environmental sounds\r\n  UI: 4              // Menu/UI sounds\r\n} as const;\r\n\r\n// Setup game audio\r\nclass GameAudioManager {\r\n  async initializeAudio(): Promise<void> {\r\n    // Background music - looped, lower volume (using default channel 0)\r\n    await queueAudio('./music/game-theme.mp3', GameChannels.MUSIC, {\r\n      loop: true,\r\n      volume: 0.4\r\n    });\r\n    \r\n    // Set channel volumes\r\n    setChannelVolume(GameChannels.SFX, 0.8);\r\n    setChannelVolume(GameChannels.VOICE, 1.0);\r\n    setChannelVolume(GameChannels.AMBIENT, 0.3);\r\n    setChannelVolume(GameChannels.UI, 0.6);\r\n  }\r\n  \r\n  async playExplosion(): Promise<void> {\r\n    // SFX don't loop, higher volume for impact\r\n    await queueAudio('./sfx/explosion.wav', GameChannels.SFX);\r\n  }\r\n  \r\n  async playDialog(audioFile: string): Promise<void> {\r\n    // Dialog interrupts other voice, priority playback\r\n    await queueAudioPriority('./voice/' + audioFile, GameChannels.VOICE);\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"podcastmedia-applications",children:"Podcast/Media Applications"}),"\n",(0,i.jsx)(e.p,{children:"Channel setup for media applications:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"const MediaChannels = {\r\n  CONTENT: 0,         // Main podcast/video content\r\n  ADS: 1,             // Advertisement audio\r\n  NOTIFICATIONS: 2    // App notifications\r\n} as const;\r\n\r\nclass PodcastPlayer {\r\n  async playEpisode(episodeUrl: string): Promise<void> {\r\n    // Main content on primary channel (using default channel 0)\r\n    await queueAudio(episodeUrl);\r\n  }\r\n  \r\n  async insertAd(adUrl: string): Promise<void> {\r\n    // Pause main content\r\n    pauseChannel(MediaChannels.CONTENT);\r\n    \r\n    // Play ad with priority (interrupts anything on ads channel)\r\n    await queueAudioPriority(adUrl, MediaChannels.ADS);\r\n    \r\n    // Resume main content when ad finishes\r\n    onAudioComplete(MediaChannels.ADS, () => {\r\n      resumeChannel(MediaChannels.CONTENT);\r\n    });\r\n  }\r\n  \r\n  async showNotification(notificationSound: string): Promise<void> {\r\n    // Brief notification sound, doesn't interrupt content\r\n    await queueAudio(notificationSound, MediaChannels.NOTIFICATIONS, {\r\n      volume: 0.7\r\n    });\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"interactive-applications",children:"Interactive Applications"}),"\n",(0,i.jsx)(e.p,{children:"Channel organization for interactive presentations or educational apps:"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"const InteractiveChannels = {\r\n  BACKGROUND: 0,      // Ambient background audio\r\n  NARRATION: 1,       // Main narration/instruction\r\n  FEEDBACK: 2,        // User interaction feedback\r\n  ALERTS: 3          // Important alerts/warnings\r\n} as const;\r\n\r\nclass InteractivePresentation {\r\n  async startLesson(): Promise<void> {\r\n    // Ambient background (using default channel 0)\r\n    await queueAudio('./audio/classroom-ambient.mp3', InteractiveChannels.BACKGROUND, {\r\n      loop: true,\r\n      volume: 0.2\r\n    });\r\n    \r\n    // Main narration\r\n    await queueAudio('./audio/lesson-intro.mp3', InteractiveChannels.NARRATION);\r\n  }\r\n  \r\n  async onUserClick(): Promise<void> {\r\n    // Quick feedback sound\r\n    await queueAudio('./audio/click-success.wav', InteractiveChannels.FEEDBACK, {\r\n      volume: 0.5\r\n    });\r\n  }\r\n  \r\n  async showAlert(alertType: 'warning' | 'error' | 'success'): Promise<void> {\r\n    // Alert interrupts narration but not background\r\n    await queueAudioPriority(`./audio/alert-${alertType}.mp3`, InteractiveChannels.ALERTS);\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"channel-management-best-practices",children:"Channel Management Best Practices"}),"\n",(0,i.jsx)(e.h3,{id:"resource-management",children:"Resource Management"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"class ChannelManager {\r\n  private activeChannels: Set<number> = new Set();\r\n  \r\n  async activateChannel(channel: number): Promise<void> {\r\n    this.activeChannels.add(channel);\r\n    console.log(`Channel ${channel} activated`);\r\n  }\r\n  \r\n  async deactivateChannel(channel: number): Promise<void> {\r\n    // Stop all audio on channel\r\n    if (channel === 0) {\r\n      // Use default for channel 0\r\n      stopCurrentAudioInChannel();\r\n    } else {\r\n      stopCurrentAudioInChannel(channel);\r\n    }\r\n    \r\n    // Clear queue\r\n    const snapshot = channel === 0 ? getQueueSnapshot() : getQueueSnapshot(channel);\r\n    if (snapshot.totalItems > 0) {\r\n      console.log(`Clearing ${snapshot.totalItems} items from channel ${channel}`);\r\n    }\r\n    \r\n    this.activeChannels.delete(channel);\r\n  }\r\n  \r\n  getActiveChannels(): number[] {\r\n    return Array.from(this.activeChannels);\r\n  }\r\n  \r\n  async stopAllChannels(): Promise<void> {\r\n    for (const channel of this.activeChannels) {\r\n      await this.deactivateChannel(channel);\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"volume-balancing",children:"Volume Balancing"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"class VolumeManager {\r\n  private channelVolumes: Map<number, number> = new Map();\r\n  \r\n  setBalancedVolumes(): void {\r\n    // Gaming balance example\r\n    this.setChannelVolume(0, 0.4);  // Music - subtle\r\n    this.setChannelVolume(1, 0.8);  // SFX - prominent\r\n    this.setChannelVolume(2, 1.0);  // Voice - full volume\r\n    this.setChannelVolume(3, 0.3);  // Ambient - background\r\n  }\r\n  \r\n  setChannelVolume(channel: number, volume: number): void {\r\n    const clampedVolume = Math.max(0, Math.min(1, volume));\r\n    setChannelVolume(channel, clampedVolume);\r\n    this.channelVolumes.set(channel, clampedVolume);\r\n  }\r\n  \r\n  duckChannels(exceptChannel: number, duckLevel: number = 0.3): void {\r\n    // Reduce volume on all channels except one (e.g., for voice priority)\r\n    for (const [channel, originalVolume] of this.channelVolumes) {\r\n      if (channel !== exceptChannel) {\r\n        setChannelVolume(channel, originalVolume * duckLevel);\r\n      }\r\n    }\r\n  }\r\n  \r\n  restoreChannelVolumes(): void {\r\n    // Restore original volumes\r\n    for (const [channel, volume] of this.channelVolumes) {\r\n      setChannelVolume(channel, volume);\r\n    }\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"event-coordination",children:"Event Coordination"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"class ChannelEventCoordinator {\r\n  setupCrossChannelEvents(): void {\r\n    // When voice starts, duck other audio\r\n    onAudioStart(2, () => {\r\n      console.log('Voice started - ducking other channels');\r\n      duckChannelVolume(0, 0.3); // Duck music\r\n      duckChannelVolume(1, 0.5); // Duck SFX slightly\r\n    });\r\n    \r\n    // When voice ends, restore volumes\r\n    onAudioComplete(2, () => {\r\n      console.log('Voice completed - restoring volumes');\r\n      restoreChannelVolume(0);\r\n      restoreChannelVolume(1);\r\n    });\r\n    \r\n    // When music changes, log transition\r\n    onAudioStart(0, (info) => {\r\n      console.log(`Music changed to: ${info.fileName}`);\r\n    });\r\n    \r\n    // Monitor queue changes across channels\r\n    [0, 1, 2].forEach(channel => {\r\n      onQueueChange(channel, (snapshot) => {\r\n        if (snapshot.totalItems > 5) {\r\n          console.warn(`Channel ${channel} queue is getting long: ${snapshot.totalItems} items`);\r\n        }\r\n      });\r\n    });\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,i.jsx)(e.h3,{id:"optimal-channel-count",children:"Optimal Channel Count"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"// Recommended limits for different scenarios\r\nconst ChannelLimits = {\r\n  MOBILE: 4,      // Conservative for mobile devices\r\n  DESKTOP: 8,     // Good balance for desktop apps\r\n  POWERFUL: 16    // For high-end applications\r\n};\r\n\r\nclass PerformanceAwareChannelManager {\r\n  private maxChannels: number;\r\n  \r\n  constructor(maxChannels: number = ChannelLimits.DESKTOP) {\r\n    this.maxChannels = maxChannels;\r\n  }\r\n  \r\n  canUseChannel(channel: number): boolean {\r\n    if (channel >= this.maxChannels) {\r\n      console.warn(`Channel ${channel} exceeds recommended limit of ${this.maxChannels}`);\r\n      return false;\r\n    }\r\n    return true;\r\n  }\r\n  \r\n  getRecommendedChannelCount(): number {\r\n    // Detect environment and return appropriate limit\r\n    const isMobile = /Android|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);\r\n    return isMobile ? ChannelLimits.MOBILE : ChannelLimits.DESKTOP;\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-typescript",children:"class ChannelMemoryManager {\r\n  async cleanupInactiveChannels(): Promise<void> {\r\n    for (let channel = 0; channel < 10; channel++) {\r\n      const snapshot = getQueueSnapshot(channel);\r\n      const audioInfo = getCurrentAudioInfo(channel);\r\n      \r\n      // Clean up channels with no activity\r\n      if (!snapshot.isChannelActive && !audioInfo) {\r\n        console.log(`Cleaning up inactive channel ${channel}`);\r\n        // Channel cleanup is automatic, but good to track\r\n      }\r\n    }\r\n  }\r\n  \r\n  getChannelMemoryUsage(): { [channel: number]: { queueSize: number; isActive: boolean } } {\r\n    const usage: { [channel: number]: { queueSize: number; isActive: boolean } } = {};\r\n    \r\n    for (let channel = 0; channel < 10; channel++) {\r\n      const snapshot = getQueueSnapshot(channel);\r\n      usage[channel] = {\r\n        queueSize: snapshot.totalItems,\r\n        isActive: snapshot.isChannelActive\r\n      };\r\n    }\r\n    \r\n    return usage;\r\n  }\r\n}\n"})}),"\n",(0,i.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(e.p,{children:"Now that you understand audio channels, explore:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/audio-queue-docs/core-concepts/queue-system",children:"Queue System"})})," - How queuing works within channels"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/audio-queue-docs/core-concepts/event-system",children:"Event System"})})," - Managing events across channels"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/audio-queue-docs/core-concepts/audio-lifecycle",children:"Audio Lifecycle"})})," - Complete audio playback flow"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:(0,i.jsx)(e.a,{href:"/audio-queue-docs/core-concepts/performance-memory",children:"Performance & Memory"})})," - Optimization strategies"]}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(u,{...n})}):u(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>t,x:()=>s});var r=a(6540);const i={},o=r.createContext(i);function t(n){const e=r.useContext(o);return r.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:t(n.components),r.createElement(o.Provider,{value:e},n.children)}}}]);