"use strict";(self.webpackChunkaudio_queue_docs=self.webpackChunkaudio_queue_docs||[]).push([[688],{7696:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>u,frontMatter:()=>t,metadata:()=>i,toc:()=>a});const i=JSON.parse('{"id":"api-reference/types-interfaces","title":"Types & Interfaces","description":"Complete TypeScript definitions for all types and interfaces used in the audio-channel-queue package.","source":"@site/docs/api-reference/types-interfaces.md","sourceDirName":"api-reference","slug":"/api-reference/types-interfaces","permalink":"/audio-queue-docs/api-reference/types-interfaces","draft":false,"unlisted":false,"editUrl":"https://github.com/tonycarpenter21/audio-queue-docs/tree/main/docs/api-reference/types-interfaces.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Audio Information","permalink":"/audio-queue-docs/api-reference/audio-information"},"next":{"title":"Basic Usage Examples","permalink":"/audio-queue-docs/examples/basic-usage"}}');var l=r(4848),s=r(8453);const t={},o="Types & Interfaces",d={},a=[{value:"Core Interfaces",id:"core-interfaces",level:2},{value:"AudioInfo",id:"audioinfo",level:3},{value:"Properties",id:"properties",level:4},{value:"Usage Examples",id:"usage-examples",level:4},{value:"AudioOptions",id:"audiooptions",level:3},{value:"Properties",id:"properties-1",level:4},{value:"Usage Examples",id:"usage-examples-1",level:4},{value:"QueueSnapshot",id:"queuesnapshot",level:3},{value:"Properties",id:"properties-2",level:4},{value:"Usage Examples",id:"usage-examples-2",level:4},{value:"QueueItem",id:"queueitem",level:3},{value:"Properties",id:"properties-3",level:4},{value:"Usage Examples",id:"usage-examples-3",level:4},{value:"Event Info Interfaces",id:"event-info-interfaces",level:2},{value:"AudioStartInfo",id:"audiostartinfo",level:3},{value:"Properties",id:"properties-4",level:4},{value:"Usage Examples",id:"usage-examples-4",level:4},{value:"AudioCompleteInfo",id:"audiocompleteinfo",level:3},{value:"Properties",id:"properties-5",level:4},{value:"Usage Examples",id:"usage-examples-5",level:4},{value:"AudioProgressInfo",id:"audioprogressinfo",level:3},{value:"Properties",id:"properties-6",level:4},{value:"Usage Examples",id:"usage-examples-6",level:4},{value:"Utility Types",id:"utility-types",level:2},{value:"ChannelNumber",id:"channelnumber",level:3},{value:"Usage Examples",id:"usage-examples-7",level:4},{value:"VolumeLevel",id:"volumelevel",level:3},{value:"Usage Examples",id:"usage-examples-8",level:4},{value:"AudioFilePath",id:"audiofilepath",level:3},{value:"Usage Examples",id:"usage-examples-9",level:4},{value:"Advanced Type Patterns",id:"advanced-type-patterns",level:2},{value:"Custom Event Handlers",id:"custom-event-handlers",level:3},{value:"Channel State Management",id:"channel-state-management",level:3},{value:"Audio Configuration Types",id:"audio-configuration-types",level:3},{value:"Type Guards",id:"type-guards",level:2},{value:"Generic Types",id:"generic-types",level:2}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,s.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"types--interfaces",children:"Types & Interfaces"})}),"\n",(0,l.jsx)(n.p,{children:"Complete TypeScript definitions for all types and interfaces used in the audio-channel-queue package."}),"\n",(0,l.jsx)(n.h2,{id:"core-interfaces",children:"Core Interfaces"}),"\n",(0,l.jsx)(n.h3,{id:"audioinfo",children:"AudioInfo"}),"\n",(0,l.jsx)(n.p,{children:"Detailed information about currently playing audio on a channel."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface AudioInfo {\r\n  audioElement: HTMLAudioElement;\r\n  currentTime: number;\r\n  duration: number;\r\n  fileName: string;\r\n  isLooping: boolean;\r\n  isPaused: boolean;\r\n  isPlaying: boolean;\r\n  volume: number;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"audioElement"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"HTMLAudioElement"})}),(0,l.jsx)(n.td,{children:"The underlying HTML audio element"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"currentTime"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Current playback position in milliseconds"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"duration"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Total audio duration in milliseconds"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"fileName"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"string"})}),(0,l.jsx)(n.td,{children:"Name of the audio file (cleaned)"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"isLooping"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:"Whether the audio is set to loop"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"isPaused"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:"Whether the audio is currently paused"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"isPlaying"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:"Whether the audio is currently playing"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"volume"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Current volume level (0.0 to 1.0)"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { getCurrentAudioInfo } from 'audio-channel-queue';\r\n\r\nconst info: AudioInfo | null = getCurrentAudioInfo();\r\nif (info) {\r\n  console.log(`${info.fileName} - ${info.currentTime}/${info.duration}ms`);\r\n  console.log(`Volume: ${info.volume}, Paused: ${info.isPaused}`);\r\n}\n"})}),"\n",(0,l.jsx)(n.h3,{id:"audiooptions",children:"AudioOptions"}),"\n",(0,l.jsx)(n.p,{children:"Configuration options for queueing audio files."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface AudioOptions {\r\n  loop?: boolean;\r\n  priority?: boolean;\r\n  volume?: number;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties-1",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Default"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"loop"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"false"})}),(0,l.jsx)(n.td,{children:"Whether to loop the audio when it finishes"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"priority"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"false"})}),(0,l.jsxs)(n.td,{children:["If true, acts like ",(0,l.jsx)(n.code,{children:"queueAudioPriority()"})]})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"volume"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"1.0"})}),(0,l.jsx)(n.td,{children:"Initial volume level (0.0 to 1.0)"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-1",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio } from 'audio-channel-queue';\r\n\r\n// Background music with loop and reduced volume\r\nconst backgroundOptions: AudioOptions = {\r\n  loop: true,\r\n  volume: 0.3\r\n};\r\nawait queueAudio('./music/ambient.mp3', 0, backgroundOptions);\r\n\r\n// Priority announcement at full volume\r\nconst urgentOptions: AudioOptions = {\r\n  priority: true,\r\n  volume: 1.0\r\n};\r\nawait queueAudio('./voice/alert.mp3', 0, urgentOptions);\r\n\r\n// Simple sound effect with default settings\r\nawait queueAudio('./sfx/click.wav', 1, {}); // or just omit options\n"})}),"\n",(0,l.jsx)(n.h3,{id:"queuesnapshot",children:"QueueSnapshot"}),"\n",(0,l.jsx)(n.p,{children:"Complete snapshot of a channel's queue state."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface QueueSnapshot {\r\n  items: QueueItem[];\r\n  totalItems: number;\r\n  currentlyPlaying: string | null;\r\n  isChannelActive: boolean;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties-2",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"items"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"QueueItem[]"})}),(0,l.jsx)(n.td,{children:"Array of all items in the queue"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"totalItems"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Total number of items in queue"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"currentlyPlaying"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"string | null"})}),(0,l.jsx)(n.td,{children:"Filename of currently playing audio, or null"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"isChannelActive"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:"Whether the channel has any activity"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-2",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { getQueueSnapshot } from 'audio-channel-queue';\r\n\r\nconst snapshot: QueueSnapshot = getQueueSnapshot();\r\n\r\nconsole.log(`Queue has ${snapshot.totalItems} items`);\r\nconsole.log(`Currently playing: ${snapshot.currentlyPlaying || 'Nothing'}`);\r\nconsole.log(`Channel active: ${snapshot.isChannelActive}`);\r\n\r\nsnapshot.items.forEach((item, index) => {\r\n  const status = item.isCurrentlyPlaying ? 'Playing' : 'Queued';\r\n  console.log(`${item.position}. ${status}: ${item.fileName}`);\r\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"queueitem",children:"QueueItem"}),"\n",(0,l.jsx)(n.p,{children:"Individual item within a queue."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface QueueItem {\r\n  fileName: string;\r\n  duration: number;\r\n  isCurrentlyPlaying: boolean;\r\n  position: number;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties-3",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"fileName"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"string"})}),(0,l.jsx)(n.td,{children:"Name of the audio file"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"duration"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Audio duration in milliseconds"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"isCurrentlyPlaying"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:"Whether this item is currently playing"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"position"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Position in queue (1-based index)"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-3",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { getQueueSnapshot } from 'audio-channel-queue';\r\n\r\nconst snapshot = getQueueSnapshot();\r\n\r\nsnapshot.items.forEach((item: QueueItem) => {\r\n  const duration = Math.round(item.duration / 1000);\r\n  const status = item.isCurrentlyPlaying ? '\ud83d\udd0a' : '\u23f3';\r\n  console.log(`${status} ${item.position}. ${item.fileName} (${duration}s)`);\r\n});\n"})}),"\n",(0,l.jsx)(n.h2,{id:"event-info-interfaces",children:"Event Info Interfaces"}),"\n",(0,l.jsx)(n.h3,{id:"audiostartinfo",children:"AudioStartInfo"}),"\n",(0,l.jsx)(n.p,{children:"Information provided when audio starts playing."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface AudioStartInfo {\r\n  audioElement: HTMLAudioElement;\r\n  currentTime: number;\r\n  duration: number;\r\n  fileName: string;\r\n  volume: number;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties-4",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"audioElement"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"HTMLAudioElement"})}),(0,l.jsx)(n.td,{children:"The HTML audio element that started"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"currentTime"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Starting playback position (usually 0)"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"duration"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Total duration of the audio file"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"fileName"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"string"})}),(0,l.jsx)(n.td,{children:"Name of the audio file"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"volume"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Volume level when playback started"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-4",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { onAudioStart } from 'audio-channel-queue';\r\n\r\nonAudioStart(0, (info: AudioStartInfo) => {\r\n  console.log(`Started: ${info.fileName}`);\r\n  console.log(`Duration: ${Math.round(info.duration / 1000)} seconds`);\r\n  console.log(`Volume: ${Math.round(info.volume * 100)}%`);\r\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"audiocompleteinfo",children:"AudioCompleteInfo"}),"\n",(0,l.jsx)(n.p,{children:"Information provided when audio finishes playing."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface AudioCompleteInfo {\r\n  fileName: string;\r\n  playbackDuration: number;\r\n  remainingInQueue: number;\r\n  wasInterrupted: boolean;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties-5",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"fileName"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"string"})}),(0,l.jsx)(n.td,{children:"Name of the audio file that completed"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"playbackDuration"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"How long the audio actually played"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"remainingInQueue"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Number of items left in queue"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"wasInterrupted"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"boolean"})}),(0,l.jsx)(n.td,{children:"Whether playback was stopped before completion"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-5",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { onAudioComplete } from 'audio-channel-queue';\r\n\r\nonAudioComplete(0, (info: AudioCompleteInfo) => {\r\n  if (info.wasInterrupted) {\r\n    console.log(`${info.fileName} was interrupted after ${info.playbackDuration}ms`);\r\n  } else {\r\n    console.log(`${info.fileName} completed naturally`);\r\n  }\r\n  console.log(`${info.remainingInQueue} items remaining in queue`);\r\n});\n"})}),"\n",(0,l.jsx)(n.h3,{id:"audioprogressinfo",children:"AudioProgressInfo"}),"\n",(0,l.jsx)(n.p,{children:"Information provided during audio playback progress updates."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface AudioProgressInfo {\r\n  currentTime: number;\r\n  duration: number;\r\n  fileName: string;\r\n  progress: number;\r\n}\n"})}),"\n",(0,l.jsx)(n.h4,{id:"properties-6",children:"Properties"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Property"}),(0,l.jsx)(n.th,{children:"Type"}),(0,l.jsx)(n.th,{children:"Description"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"currentTime"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Current playback position in milliseconds"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"duration"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Total duration in milliseconds"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"fileName"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"string"})}),(0,l.jsx)(n.td,{children:"Name of the audio file"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"progress"})}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.code,{children:"number"})}),(0,l.jsx)(n.td,{children:"Progress as decimal (0.0 to 1.0)"})]})]})]}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-6",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { onAudioProgress } from 'audio-channel-queue';\r\n\r\nonAudioProgress(0, (info: AudioProgressInfo) => {\r\n  const percentage = Math.round(info.progress * 100);\r\n  console.log(`${info.fileName}: ${percentage}%`);\r\n  console.log(`Time: ${info.currentTime}/${info.duration}ms`);\r\n});\n"})}),"\n",(0,l.jsx)(n.h2,{id:"utility-types",children:"Utility Types"}),"\n",(0,l.jsx)(n.h3,{id:"channelnumber",children:"ChannelNumber"}),"\n",(0,l.jsx)(n.p,{children:"Type alias for channel numbers."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"type ChannelNumber = number;\n"})}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-7",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio } from 'audio-channel-queue';\r\n\r\nconst musicChannel: ChannelNumber = 0;\r\nconst sfxChannel: ChannelNumber = 1;\r\nconst voiceChannel: ChannelNumber = 2;\r\n\r\nawait queueAudio('./music/background.mp3', musicChannel);\r\nawait queueAudio('./sfx/explosion.wav', sfxChannel);\r\nawait queueAudio('./voice/dialog.mp3', voiceChannel);\n"})}),"\n",(0,l.jsx)(n.h3,{id:"volumelevel",children:"VolumeLevel"}),"\n",(0,l.jsx)(n.p,{children:"Type alias for volume levels with constraints."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"type VolumeLevel = number; // 0.0 to 1.0\n"})}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-8",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { setChannelVolume } from 'audio-channel-queue';\r\n\r\nconst muteVolume: VolumeLevel = 0.0;\r\nconst halfVolume: VolumeLevel = 0.5;\r\nconst maxVolume: VolumeLevel = 1.0;\r\n\r\nsetChannelVolume(0, halfVolume);\r\nsetChannelVolume(1, maxVolume);\r\n\r\n// Volume validation helper\r\nfunction setValidVolume(channel: number, volume: VolumeLevel): void {\r\n  const clampedVolume = Math.max(0, Math.min(1, volume));\r\n  setChannelVolume(channel, clampedVolume);\r\n}\n"})}),"\n",(0,l.jsx)(n.h3,{id:"audiofilepath",children:"AudioFilePath"}),"\n",(0,l.jsx)(n.p,{children:"Type alias for audio file paths and URLs."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"type AudioFilePath = string;\n"})}),"\n",(0,l.jsx)(n.h4,{id:"usage-examples-9",children:"Usage Examples"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"import { queueAudio } from 'audio-channel-queue';\r\n\r\nconst localFile: AudioFilePath = './audio/music.mp3';\r\nconst webUrl: AudioFilePath = 'https://example.com/audio/song.mp3';\r\nconst dataUrl: AudioFilePath = 'data:audio/mp3;base64,SUQzBAAAAAAAI1RTU0UAAAA...';\r\n\r\nawait queueAudio(localFile, 0);\r\nawait queueAudio(webUrl, 1);\r\nawait queueAudio(dataUrl, 2);\n"})}),"\n",(0,l.jsx)(n.h2,{id:"advanced-type-patterns",children:"Advanced Type Patterns"}),"\n",(0,l.jsx)(n.h3,{id:"custom-event-handlers",children:"Custom Event Handlers"}),"\n",(0,l.jsx)(n.p,{children:"Define strongly-typed event handler functions."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"type AudioStartHandler = (info: AudioStartInfo) => void;\r\ntype AudioCompleteHandler = (info: AudioCompleteInfo) => void;\r\ntype AudioProgressHandler = (info: AudioProgressInfo) => void;\r\ntype QueueChangeHandler = (snapshot: QueueSnapshot) => void;\r\n\r\n// Usage examples\r\nconst handleStart: AudioStartHandler = (info) => {\r\n  console.log(`Started: ${info.fileName}`);\r\n};\r\n\r\nconst handleComplete: AudioCompleteHandler = (info) => {\r\n  console.log(`Completed: ${info.fileName}`);\r\n};\r\n\r\nconst handleProgress: AudioProgressHandler = (info) => {\r\n  updateProgressDisplay(info.progress);\r\n};\r\n\r\nconst handleQueueChange: QueueChangeHandler = (snapshot) => {\r\n  updateQueueDisplay(snapshot.items);\r\n};\n"})}),"\n",(0,l.jsx)(n.h3,{id:"channel-state-management",children:"Channel State Management"}),"\n",(0,l.jsx)(n.p,{children:"Create typed channel state interfaces."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface ChannelState {\r\n  audioInfo: AudioInfo | null;\r\n  isPaused: boolean;\r\n  isActive: boolean;\r\n  queueSnapshot: QueueSnapshot;\r\n  volume: VolumeLevel;\r\n}\r\n\r\ninterface MultiChannelState {\r\n  [channelNumber: number]: ChannelState;\r\n}\r\n\r\n// Usage example\r\nclass AudioChannelManager {\r\n  private channelStates: MultiChannelState = {};\r\n\r\n  getChannelState(channel: ChannelNumber): ChannelState | null {\r\n    return this.channelStates[channel] || null;\r\n  }\r\n\r\n  updateChannelState(channel: ChannelNumber, state: Partial<ChannelState>): void {\r\n    this.channelStates[channel] = {\r\n      ...this.channelStates[channel],\r\n      ...state\r\n    };\r\n  }\r\n\r\n  getAllChannelStates(): MultiChannelState {\r\n    return { ...this.channelStates };\r\n  }\r\n}\n"})}),"\n",(0,l.jsx)(n.h3,{id:"audio-configuration-types",children:"Audio Configuration Types"}),"\n",(0,l.jsx)(n.p,{children:"Create configuration interfaces for different audio scenarios."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"interface GameAudioConfig {\r\n  music: {\r\n    channel: ChannelNumber;\r\n    volume: VolumeLevel;\r\n    loop: boolean;\r\n  };\r\n  sfx: {\r\n    channel: ChannelNumber;\r\n    volume: VolumeLevel;\r\n  };\r\n  voice: {\r\n    channel: ChannelNumber;\r\n    volume: VolumeLevel;\r\n    priority: boolean;\r\n  };\r\n}\r\n\r\ninterface PodcastConfig {\r\n  episode: {\r\n    channel: ChannelNumber;\r\n    volume: VolumeLevel;\r\n  };\r\n  ads: {\r\n    channel: ChannelNumber;\r\n    volume: VolumeLevel;\r\n    priority: boolean;\r\n  };\r\n}\r\n\r\n// Usage examples\r\nconst gameConfig: GameAudioConfig = {\r\n  music: { channel: 0, volume: 0.4, loop: true },\r\n  sfx: { channel: 1, volume: 0.8 },\r\n  voice: { channel: 2, volume: 1.0, priority: true }\r\n};\r\n\r\nconst podcastConfig: PodcastConfig = {\r\n  episode: { channel: 0, volume: 1.0 },\r\n  ads: { channel: 0, volume: 0.9, priority: true }\r\n};\n"})}),"\n",(0,l.jsx)(n.h2,{id:"type-guards",children:"Type Guards"}),"\n",(0,l.jsx)(n.p,{children:"Utility functions for type checking and validation."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"// Check if a value is a valid AudioInfo object\r\nfunction isAudioInfo(value: any): value is AudioInfo {\r\n  return value &&\r\n    typeof value === 'object' &&\r\n    typeof value.fileName === 'string' &&\r\n    typeof value.currentTime === 'number' &&\r\n    typeof value.duration === 'number' &&\r\n    typeof value.volume === 'number' &&\r\n    typeof value.isPlaying === 'boolean' &&\r\n    typeof value.isPaused === 'boolean' &&\r\n    typeof value.isLooping === 'boolean';\r\n}\r\n\r\n// Check if a value is a valid volume level\r\nfunction isValidVolume(value: any): value is VolumeLevel {\r\n  return typeof value === 'number' && value >= 0 && value <= 1;\r\n}\r\n\r\n// Check if a value is a valid channel number\r\nfunction isValidChannel(value: any): value is ChannelNumber {\r\n  return typeof value === 'number' && value >= 0 && Number.isInteger(value);\r\n}\r\n\r\n// Usage examples\r\nconst audioInfo = getCurrentAudioInfo(0);\r\nif (isAudioInfo(audioInfo)) {\r\n  // TypeScript now knows audioInfo is AudioInfo, not AudioInfo | null\r\n  console.log(`Playing: ${audioInfo.fileName}`);\r\n}\r\n\r\nfunction setValidatedVolume(channel: number, volume: any): boolean {\r\n  if (!isValidChannel(channel)) {\r\n    console.error('Invalid channel number');\r\n    return false;\r\n  }\r\n  \r\n  if (!isValidVolume(volume)) {\r\n    console.error('Invalid volume level');\r\n    return false;\r\n  }\r\n  \r\n  setChannelVolume(channel, volume);\r\n  return true;\r\n}\n"})}),"\n",(0,l.jsx)(n.h2,{id:"generic-types",children:"Generic Types"}),"\n",(0,l.jsx)(n.p,{children:"Create reusable generic types for audio management."}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-typescript",children:"// Generic event handler type\r\ntype EventHandler<T> = (data: T) => void;\r\n\r\n// Audio event handlers\r\ntype AudioEventHandlers = {\r\n  onStart: EventHandler<AudioStartInfo>;\r\n  onComplete: EventHandler<AudioCompleteInfo>;\r\n  onProgress: EventHandler<AudioProgressInfo>;\r\n  onQueueChange: EventHandler<QueueSnapshot>;\r\n};\r\n\r\n// Channel-specific configuration\r\ninterface ChannelConfig<TOptions = AudioOptions> {\r\n  channel: ChannelNumber;\r\n  defaultOptions: TOptions;\r\n  eventHandlers: Partial<AudioEventHandlers>;\r\n}\r\n\r\n// Usage example\r\nconst musicChannelConfig: ChannelConfig = {\r\n  channel: 0,\r\n  defaultOptions: { loop: true, volume: 0.5 },\r\n  eventHandlers: {\r\n    onStart: (info) => console.log(`Music started: ${info.fileName}`),\r\n    onComplete: (info) => console.log(`Music completed: ${info.fileName}`)\r\n  }\r\n};\n"})}),"\n",(0,l.jsxs)(n.p,{children:["This completes the comprehensive ",(0,l.jsx)(n.strong,{children:"Types & Interfaces"})," documentation! \ud83c\udf89"]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>o});var i=r(6540);const l={},s=i.createContext(l);function t(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:t(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);